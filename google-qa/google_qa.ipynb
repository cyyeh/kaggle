{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google-qa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c5d7221d03041cb936563e6d3e64ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_46a3c2ffc72044f1b904b36617636496",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b9577ae944347ba98776688865e224a",
              "IPY_MODEL_a76c50181a7c4c09b2e71b006dfbbdd9"
            ]
          }
        },
        "46a3c2ffc72044f1b904b36617636496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b9577ae944347ba98776688865e224a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e4fd4fea0704a62b6cb9a96b06da776",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0916dc36013c4d429a04a4581d304195"
          }
        },
        "a76c50181a7c4c09b2e71b006dfbbdd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_57e4ea4b1e244de4929e284c9947f5b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 213k/213k [00:00&lt;00:00, 387kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddd488947a7c4b7da01d9da82d127e99"
          }
        },
        "2e4fd4fea0704a62b6cb9a96b06da776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0916dc36013c4d429a04a4581d304195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57e4ea4b1e244de4929e284c9947f5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddd488947a7c4b7da01d9da82d127e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyyeh/kaggle/blob/master/google-qa/google_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oLbtZU7ouH-",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This notbook demonstrates how to train/evaluate/test short answer classification task based on Google Natural Question dataset using BERT.\n",
        "\n",
        "## General Steps to Solve This Problem\n",
        "\n",
        "1. [X] Prepare raw data\n",
        "2. [ ] Transform raw data into BERT compatiple format\n",
        "3. [ ] Add new layers for downstream task on the BERT model\n",
        "4. [ ] Train the model\n",
        "5. [ ] Make inference on new data\n",
        "\n",
        "### References\n",
        "\n",
        "- [進擊的 BERT：NLP 界的巨人之力與遷移學習](https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVptgN32lQcp",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-T2r-tyyRwN",
        "colab_type": "code",
        "outputId": "d4da5e7a-0970-4302-d1da-52f02763da3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl3zrHLT8BvF",
        "colab_type": "code",
        "outputId": "9a3a53a0-ea79-447f-dbf7-e2c85ce8e9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!pip install transformers # BertModel"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from transformers) (1.18.1)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from transformers) (2.22.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (1.25.8)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ehmlmDf73e_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFjdY_FQHDDZ",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Raw Data\n",
        "\n",
        "Note: You don't need to run code inside the \"Prepare Kaggle Dataset\" section, since it's written to make you understand how is the dataset generated from raw Kaggle dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3sbfCf0UXu5",
        "colab_type": "code",
        "outputId": "eba59cf1-b3fe-4997-c19f-ed77caadcfd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CKOinmsWByl",
        "colab_type": "code",
        "outputId": "b42b248e-b25a-4e3e-8208-9e5480ae4f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "# load training data and check if it's ok\n",
        "simplified_train_csv_path = \"drive/My Drive/simplified-nq-train.csv\"\n",
        "\n",
        "simplified_train_pd = pd.read_csv(simplified_train_csv_path, sep=';', chunksize=1)\n",
        "next(simplified_train_pd)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>long_answer_candidates</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5655493461695504401</td>\n",
              "      <td>which is the most common use of opt-in e-mail ...</td>\n",
              "      <td>['&lt;Table&gt; &lt;Tr&gt; &lt;Td&gt; &lt;/Td&gt; &lt;Td&gt; ( hide ) This a...</td>\n",
              "      <td>{'yes_no_answer': 'NONE', 'long_answer': {'sta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            example_id  ...                                        annotations\n",
              "0  5655493461695504401  ...  {'yes_no_answer': 'NONE', 'long_answer': {'sta...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeolX8NVPcar",
        "colab_type": "code",
        "outputId": "89d63540-8554-4f58-931c-0976365728ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load testing data and check if it's ok\n",
        "simplified_test_csv_path = \"drive/My Drive/simplified-nq-test.csv\"\n",
        "\n",
        "simplified_test_pd = pd.read_csv(simplified_test_csv_path, sep=';')\n",
        "simplified_test_pd.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>long_answer_candidates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1220107454853145579</td>\n",
              "      <td>who is the south african high commissioner in ...</td>\n",
              "      <td>['&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; High Commissio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8777415633185303067</td>\n",
              "      <td>the office episode when they sing to michael</td>\n",
              "      <td>['&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; `` Michael \\'s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4640548859154538040</td>\n",
              "      <td>what is the main idea of the cross of gold speech</td>\n",
              "      <td>['&lt;Table&gt; Cross of Gold speech &lt;Tr&gt; &lt;Td_colspa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-5316095317154496261</td>\n",
              "      <td>when was i want to sing in opera written</td>\n",
              "      <td>['&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; Wilkie Bard &lt;/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8752372642178983917</td>\n",
              "      <td>who does the voices in ice age collision course</td>\n",
              "      <td>['&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; Ice Age : Coll...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            example_id  ...                             long_answer_candidates\n",
              "0 -1220107454853145579  ...  ['<Table> <Tr> <Th_colspan=\"2\"> High Commissio...\n",
              "1  8777415633185303067  ...  ['<Table> <Tr> <Th_colspan=\"2\"> `` Michael \\'s...\n",
              "2  4640548859154538040  ...  ['<Table> Cross of Gold speech <Tr> <Td_colspa...\n",
              "3 -5316095317154496261  ...  ['<Table> <Tr> <Th_colspan=\"2\"> Wilkie Bard </...\n",
              "4 -8752372642178983917  ...  ['<Table> <Tr> <Th_colspan=\"2\"> Ice Age : Coll...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wycKI_jdbSe2",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Kaggle Dataset for [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyY2eSc6klo-",
        "colab_type": "text"
      },
      "source": [
        "### Download Question Answering Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3M1z5fhKgO3",
        "colab_type": "code",
        "outputId": "e6ce60f1-b1c6-410f-96e7-14bf414b3851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"chihyuyeh\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"f21b340fc8082977cbf954c80ad69ae1\" # key from the json file\n",
        "!kaggle competitions download -c tensorflow2-question-answering"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/18.2k [00:00<?, ?B/s]\n",
            "100% 18.2k/18.2k [00:00<00:00, 16.0MB/s]\n",
            "Downloading simplified-nq-test.jsonl.zip to /content\n",
            "  0% 0.00/4.78M [00:00<?, ?B/s]\n",
            "100% 4.78M/4.78M [00:00<00:00, 77.9MB/s]\n",
            "Downloading simplified-nq-train.jsonl.zip to /content\n",
            "100% 4.46G/4.46G [01:20<00:00, 29.4MB/s]\n",
            "100% 4.46G/4.46G [01:20<00:00, 59.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fNclz9Pk16X",
        "colab_type": "text"
      },
      "source": [
        "### Unzip Question Answering Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BXCnu4BeeN5",
        "colab_type": "code",
        "outputId": "641e8774-857f-4e35-c19e-165aa779371f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip simplified-nq-train.jsonl.zip\n",
        "!unzip simplified-nq-test.jsonl.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  simplified-nq-train.jsonl.zip\n",
            "  inflating: simplified-nq-train.jsonl  \n",
            "Archive:  simplified-nq-test.jsonl.zip\n",
            "  inflating: simplified-nq-test.jsonl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amvgDGEsItBc",
        "colab_type": "text"
      },
      "source": [
        "### Generate data I need and export it to csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0LCl-QDJr9U",
        "colab_type": "text"
      },
      "source": [
        "check data fields in simplified-nq-train.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdzpA_3_I53u",
        "colab_type": "code",
        "outputId": "a0961cf2-05ea-4f28-9c4a-75babcc28bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('simplified-nq-train.jsonl') as f:\n",
        "  line = f.readline()\n",
        "  json_obj = json.loads(line)\n",
        "  print(json_obj.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['document_text', 'long_answer_candidates', 'question_text', 'annotations', 'document_url', 'example_id'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5cTm5oyLFht",
        "colab_type": "text"
      },
      "source": [
        "Data fields in simplified-nq-train.jsonl\n",
        "- document_text\n",
        "- long_answer_candidates\n",
        "- question_text\n",
        "- annotations\n",
        "- document_url\n",
        "- example_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okamj3hALTWM",
        "colab_type": "text"
      },
      "source": [
        "check data fields in simplified-nq-test.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIr5apSDLXf2",
        "colab_type": "code",
        "outputId": "8b217ae0-f4e3-466f-9b2e-04148bcf195d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('simplified-nq-test.jsonl') as f:\n",
        "  line = f.readline()\n",
        "  json_obj = json.loads(line)\n",
        "  print(json_obj.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['example_id', 'question_text', 'document_text', 'long_answer_candidates'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg2hflM7Lgpj",
        "colab_type": "text"
      },
      "source": [
        "Data fields in simplified-nq-test.jsonl\n",
        "- example_id\n",
        "- question_text\n",
        "- document_text\n",
        "- long_answer_candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glPMScs3Lu4o",
        "colab_type": "text"
      },
      "source": [
        "Data fields that are not needed in training data:\n",
        "- document_text\n",
        "- document_url\n",
        "\n",
        "Data fields that are not needed in testing data:\n",
        "- document_text\n",
        "\n",
        "I will remove these data fields in order to reduce memory size for the dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QcFuFgEPp1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "LONG_ANSWER_CANDIDATES = 'long_answer_candidates'\n",
        "QUESTION_TEXT = 'question_text'\n",
        "ANNOTATIONS = 'annotations'\n",
        "EXAMPLE_ID = 'example_id'\n",
        "DOCUMENT_TEXT = 'document_text'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2OK1dh1lhBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_long_answer_existed(annotations):\n",
        "  long_answer = annotations['long_answer']\n",
        "  return long_answer['start_token'] != -1 \\\n",
        "  and long_answer['candidate_index'] != -1 \\\n",
        "  and long_answer['end_token'] != -1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QREZWH8MO26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write to simplified-nq-train.csv\n",
        "with open('simplified-nq-train.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=';')\n",
        "  # headline\n",
        "  writer.writerow([\n",
        "                   EXAMPLE_ID,\n",
        "                   QUESTION_TEXT,\n",
        "                   LONG_ANSWER_CANDIDATES,\n",
        "                   ANNOTATIONS\n",
        "                   ])\n",
        "\n",
        "  with open('simplified-nq-train.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "      json_obj = json.loads(line)\n",
        "      if is_long_answer_existed(json_obj[ANNOTATIONS][0]):\n",
        "        document_text = json_obj[DOCUMENT_TEXT].split(' ')\n",
        "        writer.writerow([\n",
        "                        json_obj[EXAMPLE_ID], \n",
        "                        json_obj[QUESTION_TEXT],\n",
        "                        [\n",
        "                          ' '.join(document_text[candidate['start_token']:candidate['end_token']]) \n",
        "                          for candidate in json_obj[LONG_ANSWER_CANDIDATES]\n",
        "                        ],\n",
        "                        json_obj[ANNOTATIONS][0]\n",
        "                        ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svr9VMDsPwyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write to simplified-nq-test.csv\n",
        "with open('simplified-nq-test.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=';')\n",
        "  # headline\n",
        "  writer.writerow([\n",
        "                   EXAMPLE_ID,\n",
        "                   QUESTION_TEXT, \n",
        "                   LONG_ANSWER_CANDIDATES\n",
        "                   ])\n",
        "\n",
        "  with open('simplified-nq-test.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "      json_obj = json.loads(line)\n",
        "      document_text = json_obj[DOCUMENT_TEXT].split(' ')\n",
        "\n",
        "      writer.writerow([\n",
        "                       json_obj[EXAMPLE_ID], \n",
        "                       json_obj[QUESTION_TEXT],\n",
        "                       [\n",
        "                        ' '.join(document_text[candidate['start_token']:candidate['end_token']]) \n",
        "                        for candidate in json_obj[LONG_ANSWER_CANDIDATES]\n",
        "                       ],\n",
        "                      ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hugm22sMVtOD",
        "colab_type": "text"
      },
      "source": [
        "### Move these generated csv files to my google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gTvejGEHGIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv simplified-nq-test.csv drive/My\\ Drive/\n",
        "!mv simplified-nq-train.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUvno3lZYcSp",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Short Answer Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1AFfkJX5yvS",
        "colab_type": "text"
      },
      "source": [
        "Since a short answer exists only if a long answer exists, so we will remove cases where long answers don't exist first.\n",
        "\n",
        "For long answers that exist, there are several cases of short answers:\n",
        "1. YES/NO\n",
        "2. a sentence or phrase\n",
        "3. no short answer\n",
        "\n",
        "For long answers that don't exist, `start_token`, `candidate_index`, and `end_token` are all -1 in `annotations` of `simplified-nq-train.jsonl`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5PYQ3NcYbNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Short_answer_dataset():\n",
        "  def __init__(self, tokenizer, data_path='drive/My Drive/simplified-nq-train.csv', mode='train'):\n",
        "    assert mode in ['train', 'test']\n",
        "    self.df = pd.read_csv(data_path, sep=\";\", chunksize=1)\n",
        "    self.mode = mode\n",
        "    self.tokenizer = tokenizer\n",
        "    self.yes_no_label_map = {'YES': 1, 'NO': 2, 'NONE': 3}\n",
        "\n",
        "\n",
        "  def get_dataset_generator_function(self):\n",
        "    return self._create_data_generator\n",
        "\n",
        "\n",
        "  '''\n",
        "  target_format: 'raw'|'bert'\n",
        "  '''\n",
        "  def _create_data_generator(self, target_format='bert'):\n",
        "    def _is_long_answer_existed(annotations):\n",
        "      long_answer = annotations['long_answer']\n",
        "      return long_answer['start_token'] != -1 \\\n",
        "      and long_answer['candidate_index'] != -1 \\\n",
        "      and long_answer['end_token'] != -1 \n",
        "\n",
        "    with open(self.data_path, 'r') as data:\n",
        "      temp_next_index = 0\n",
        "      for instance in data:\n",
        "        if temp_next_index == self._next_index:\n",
        "          self._next_index += 1\n",
        "          nq_json = json.loads(instance)\n",
        "          if self.mode == 'train':\n",
        "            # we only care about short answers where long answers exist\n",
        "            if _is_long_answer_existed(nq_json['annotations'][0]):\n",
        "              if target_format == 'raw':\n",
        "                yield nq_json\n",
        "              else:\n",
        "                yield self.get_bert_compatible_instance(nq_json)\n",
        "          else:\n",
        "            if target_format == 'raw':\n",
        "              yield nq_json\n",
        "            else:\n",
        "              yield self.get_bert_compatible_instance(nq_json)\n",
        "        else:\n",
        "          temp_next_index += 1 \n",
        "\n",
        "\n",
        "  '''\n",
        "  make a pair that consists of question text and long answer, then return 3 tensors\n",
        "  for the pair:\n",
        "  - tokens_tensor：tokens list made from concatenating two sentences. special tokens are included([CLS], [SEP], etc.)\n",
        "  - segments_tensor： classify the boundary of each sentence; 0 for the first sentence, 1 for the second sentence\n",
        "  - masks_tensor\n",
        "  - label_tensor： none if it's in testing mode\n",
        "  '''\n",
        "  def get_bert_compatible_instance(self, instance):\n",
        "    '''\n",
        "    helper functions\n",
        "    '''\n",
        "    def _get_question_long_answer_pair(instance):\n",
        "      question_text = instance['question_text']\n",
        "      long_answer = instance['annotations'][0]['long_answer']\n",
        "      long_answer_start_token, long_answer_end_token = long_answer['start_token'], long_answer['end_token']\n",
        "      document_text_tokenized = instance['document_text'].split(' ')\n",
        "      long_answer_text = ' '.join(document_text_tokenized[long_answer_start_token:long_answer_end_token])\n",
        "      return question_text, long_answer_text\n",
        "\n",
        "    def _get_short_answer_label(instance):\n",
        "      return instance['annotations'][0]['yes_no_answer']\n",
        "\n",
        "    ### build label_tensor\n",
        "    if self.mode == 'train':\n",
        "      short_answer_label = _get_short_answer_label(instance)\n",
        "      label_id = self.yes_no_label_map[short_answer_label]\n",
        "      label_tensor = tf.constant(label_id, dtype=tf.int64)\n",
        "    else:\n",
        "      label_tensor = None\n",
        "\n",
        "    # question_text is the first sentence(a)\n",
        "    # long_answer_text is the second sentence(b)\n",
        "    question_text, long_answer_text = _get_question_long_answer_pair(instance)\n",
        "    \n",
        "    ### build tokens_tensor\n",
        "    # first sentence\n",
        "    word_pieces = [\"[CLS]\"]\n",
        "    tokens_a = self.tokenizer.tokenize(question_text)\n",
        "    word_pieces += tokens_a + [\"[SEP]\"]\n",
        "    len_a = len(word_pieces)\n",
        "\n",
        "    # second sentence\n",
        "    tokens_b = self.tokenizer.tokenize(long_answer_text)\n",
        "    word_pieces += tokens_b + [\"[SEP]\"]\n",
        "    len_b = len(word_pieces) - len_a\n",
        "\n",
        "    ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "    tokens_tensor = tf.constant(ids, dtype=tf.int64)\n",
        "\n",
        "    ### build segments_tensor\n",
        "    segments_tensor = tf.constant([0] * len_a + [1] * len_b, dtype=tf.int64)\n",
        "\n",
        "    ### build masks_tensor\n",
        "    masks_tensors = tf.zeros(tokens_tensor.shape, dtype=tf.int64)\n",
        "    masks_tensors = tf.where(tokens_tensor != 0 , 1, 0)\n",
        "\n",
        "    return (tokens_tensor, segments_tensor, masks_tensors), label_tensor\n",
        "\n",
        "  \n",
        "  def convert_ids_to_tokens(self, tokens_tensor):\n",
        "    return self.tokenizer.convert_ids_to_tokens(tokens_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clRtbCkozf0_",
        "colab_type": "text"
      },
      "source": [
        "### Initialize BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qBpoxcnzZWp",
        "colab_type": "code",
        "outputId": "9adc5fcc-5851-40f8-8ff4-56b975d2e1f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "9c5d7221d03041cb936563e6d3e64ab6",
            "46a3c2ffc72044f1b904b36617636496",
            "1b9577ae944347ba98776688865e224a",
            "a76c50181a7c4c09b2e71b006dfbbdd9",
            "2e4fd4fea0704a62b6cb9a96b06da776",
            "0916dc36013c4d429a04a4581d304195",
            "57e4ea4b1e244de4929e284c9947f5b0",
            "ddd488947a7c4b7da01d9da82d127e99"
          ]
        }
      },
      "source": [
        "html_tags = ['<P>', '</P>', '<Table>', '</Table>', '<Tr>', '</Tr>', '<Li>', '</Li>', '<Ol>', '</Ol>', '<Dl>', '</Dl>', '<Ul>','</Ul>']\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_basic_tokenize=False)\n",
        "bert_tokenizer.add_tokens(html_tags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c5d7221d03041cb936563e6d3e64ab6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzeH5voph-z9",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8dhWJhjh94J",
        "colab_type": "code",
        "outputId": "1b2ebcbd-68ba-4758-9fcb-fb24ede2f54d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "short_answer_train_dataset_gen = Short_answer_dataset(bert_tokenizer).get_dataset_generator_function()\n",
        "ds_short_answer_train_dataset = tf.data.Dataset.from_generator(\n",
        "    short_answer_train_dataset_gen, \n",
        "    output_types=(tf.int64, tf.int64, tf.int64, tf.int64)\n",
        "\n",
        "#for a in ds_short_answer_train_dataset.take(1):\n",
        "#  print(a)\n",
        "\n",
        "#for a in ds_short_answer_train_dataset.padded_batch(10, padded_shapes=([None, None, None, None])).take(10):\n",
        "#  print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-39f7679a202d>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    for a in ds_short_answer_train_dataset.padded_batch(10, padded_shapes=([None, None, None, None])).take(10):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A0MN8aDslkc",
        "colab_type": "text"
      },
      "source": [
        "### Possible Improvements\n",
        "\n",
        "1. Use `jsonlines` package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIAtoE_4lF8D",
        "colab_type": "text"
      },
      "source": [
        "# Short Answer Idenfiticator\n",
        "\n",
        "![short-answer-identificator](https://github.com/cyyeh/kaggle/blob/master/google-qa/short_answer_identificator.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejwRXuwwn27g",
        "colab_type": "text"
      },
      "source": [
        "## Long Answer Encoder\n",
        "\n",
        "see Prepare Short Answer Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvPQV4fkn5Rm",
        "colab_type": "text"
      },
      "source": [
        "## Short Answer Binary Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ9uPnnM69h0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_VazWBfn-zy",
        "colab_type": "text"
      },
      "source": [
        "## Short Answer Null Classifier"
      ]
    }
  ]
}