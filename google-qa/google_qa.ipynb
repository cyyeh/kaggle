{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google-qa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyyeh/kaggle/blob/master/google-qa/google_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oLbtZU7ouH-",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This notbook demonstrates how to train/evaluate/test short answer classification task based on Google Natural Question dataset using BERT.\n",
        "\n",
        "## General Steps to Solve This Problem\n",
        "\n",
        "1. [X] Prepare raw data\n",
        "2. [ ] Transform raw data into BERT compatiple format\n",
        "3. [ ] Add new layers for downstream task on the BERT model\n",
        "4. [ ] Train the model\n",
        "5. [ ] Make inference on new data\n",
        "\n",
        "### References\n",
        "\n",
        "- [進擊的 BERT：NLP 界的巨人之力與遷移學習](https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVptgN32lQcp",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-T2r-tyyRwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl3zrHLT8BvF",
        "colab_type": "code",
        "outputId": "ebdd3b21-ad41-41e1-a0a3-b21278ba0b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!pip install transformers # BertModel"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from transformers) (2.22.0)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from transformers) (1.18.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ehmlmDf73e_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFjdY_FQHDDZ",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3sbfCf0UXu5",
        "colab_type": "code",
        "outputId": "eba59cf1-b3fe-4997-c19f-ed77caadcfd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wycKI_jdbSe2",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Kaggle Dataset for [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyY2eSc6klo-",
        "colab_type": "text"
      },
      "source": [
        "### Download Question Answering Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3M1z5fhKgO3",
        "colab_type": "code",
        "outputId": "6a801f4c-7f2f-4602-fb96-2fb34d6ab5b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"chihyuyeh\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"f21b340fc8082977cbf954c80ad69ae1\" # key from the json file\n",
        "!kaggle competitions download -c tensorflow2-question-answering"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/18.2k [00:00<?, ?B/s]\n",
            "100% 18.2k/18.2k [00:00<00:00, 10.2MB/s]\n",
            "Downloading simplified-nq-train.jsonl.zip to /content\n",
            "100% 4.45G/4.46G [01:21<00:00, 66.6MB/s]\n",
            "100% 4.46G/4.46G [01:21<00:00, 58.9MB/s]\n",
            "Downloading simplified-nq-test.jsonl.zip to /content\n",
            "  0% 0.00/4.78M [00:00<?, ?B/s]\n",
            "100% 4.78M/4.78M [00:00<00:00, 43.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fNclz9Pk16X",
        "colab_type": "text"
      },
      "source": [
        "### Unzip Question Answering Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BXCnu4BeeN5",
        "colab_type": "code",
        "outputId": "c0fceec4-f9f5-4830-ad0e-aa7f9cbc12b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip simplified-nq-train.jsonl.zip\n",
        "!unzip simplified-nq-test.jsonl.zip"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  simplified-nq-train.jsonl.zip\n",
            "  inflating: simplified-nq-train.jsonl  \n",
            "Archive:  simplified-nq-test.jsonl.zip\n",
            "  inflating: simplified-nq-test.jsonl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amvgDGEsItBc",
        "colab_type": "text"
      },
      "source": [
        "### Generate data I need and export it to csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0LCl-QDJr9U",
        "colab_type": "text"
      },
      "source": [
        "check data fields in simplified-nq-train.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdzpA_3_I53u",
        "colab_type": "code",
        "outputId": "6dd3cb3b-0acd-4a7a-a969-b9feb32d1d4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('simplified-nq-train.jsonl') as f:\n",
        "  line = f.readline()\n",
        "  json_obj = json.loads(line)\n",
        "  print(json_obj.keys())"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['document_text', 'long_answer_candidates', 'question_text', 'annotations', 'document_url', 'example_id'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5cTm5oyLFht",
        "colab_type": "text"
      },
      "source": [
        "Data fields in simplified-nq-train.jsonl\n",
        "- document_text\n",
        "- long_answer_candidates\n",
        "- question_text\n",
        "- annotations\n",
        "- document_url\n",
        "- example_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okamj3hALTWM",
        "colab_type": "text"
      },
      "source": [
        "check data fields in simplified-nq-test.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIr5apSDLXf2",
        "colab_type": "code",
        "outputId": "a6727251-45f3-4c04-a492-9b6c806dd46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('simplified-nq-test.jsonl') as f:\n",
        "  line = f.readline()\n",
        "  json_obj = json.loads(line)\n",
        "  print(json_obj.keys())"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['example_id', 'question_text', 'document_text', 'long_answer_candidates'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg2hflM7Lgpj",
        "colab_type": "text"
      },
      "source": [
        "Data fields in simplified-nq-test.jsonl\n",
        "- example_id\n",
        "- question_text\n",
        "- document_text\n",
        "- long_answer_candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glPMScs3Lu4o",
        "colab_type": "text"
      },
      "source": [
        "Data fields that are not needed in training data:\n",
        "- document_text\n",
        "- document_url\n",
        "\n",
        "Data fields that are not needed in testing data:\n",
        "- document_text\n",
        "\n",
        "I will remove these data fields in order to reduce memory size for the dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QcFuFgEPp1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "LONG_ANSWER_CANDIDATES = 'long_answer_candidates'\n",
        "QUESTION_TEXT = 'question_text'\n",
        "ANNOTATIONS = 'annotations'\n",
        "EXAMPLE_ID = 'example_id'\n",
        "DOCUMENT_TEXT = 'document_text'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77m1C2HRw0Ti",
        "colab_type": "text"
      },
      "source": [
        "Since a short answer exists only if a long answer exists, so we will remove cases where long answers don't exist first.\n",
        "\n",
        "For long answers that don't exist, `start_token`, `candidate_index`, and `end_token` are all -1 in `annotations` of `simplified-nq-train.jsonl`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2OK1dh1lhBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_long_answer_existed(annotations):\n",
        "  long_answer = annotations['long_answer']\n",
        "  return long_answer['start_token'] != -1 \\\n",
        "  and long_answer['candidate_index'] != -1 \\\n",
        "  and long_answer['end_token'] != -1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d9yy_i61quM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_annotation_dataset(document_text, annotations):\n",
        "  orig_long_answer = annotations['long_answer']\n",
        "  new_long_answer = ' '.join(document_text[\n",
        "                                       orig_long_answer['start_token']:\n",
        "                                       orig_long_answer['end_token']\n",
        "                                      ])\n",
        "  orig_short_answer = annotations['short_answers']\n",
        "  new_short_answer = ' '.join(document_text[\n",
        "                                            orig_short_answer[0]['start_token']:\n",
        "                                            orig_short_answer[0]['end_token']\n",
        "                                          ]) if len(orig_short_answer) else ''\n",
        "  return {\n",
        "      \"yes_no_answer\": annotations[\"yes_no_answer\"],\n",
        "      \"long_answer\": new_long_answer,\n",
        "      \"short_answer\": new_short_answer\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QREZWH8MO26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write to simplified-nq-train.csv\n",
        "with open('simplified-nq-train.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=';')\n",
        "  # headline\n",
        "  writer.writerow([\n",
        "                   EXAMPLE_ID,\n",
        "                   QUESTION_TEXT,\n",
        "                   LONG_ANSWER_CANDIDATES,\n",
        "                   ANNOTATIONS\n",
        "                   ])\n",
        "\n",
        "  with open('simplified-nq-train.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "      json_obj = json.loads(line)\n",
        "      if is_long_answer_existed(json_obj[ANNOTATIONS][0]):\n",
        "        document_text = json_obj[DOCUMENT_TEXT].split(' ')\n",
        "        writer.writerow([\n",
        "                        json_obj[EXAMPLE_ID], \n",
        "                        json_obj[QUESTION_TEXT],\n",
        "                        [\n",
        "                          ' '.join(document_text[candidate['start_token']:candidate['end_token']]) \n",
        "                          for candidate in json_obj[LONG_ANSWER_CANDIDATES]\n",
        "                        ],\n",
        "                        make_annotation_dataset(document_text, json_obj[ANNOTATIONS][0])\n",
        "                        ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svr9VMDsPwyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write to simplified-nq-test.csv\n",
        "with open('simplified-nq-test.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=';')\n",
        "  # headline\n",
        "  writer.writerow([\n",
        "                   EXAMPLE_ID,\n",
        "                   QUESTION_TEXT, \n",
        "                   LONG_ANSWER_CANDIDATES\n",
        "                   ])\n",
        "\n",
        "  with open('simplified-nq-test.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "      json_obj = json.loads(line)\n",
        "      document_text = json_obj[DOCUMENT_TEXT].split(' ')\n",
        "\n",
        "      writer.writerow([\n",
        "                       json_obj[EXAMPLE_ID], \n",
        "                       json_obj[QUESTION_TEXT],\n",
        "                       [\n",
        "                        ' '.join(document_text[candidate['start_token']:candidate['end_token']]) \n",
        "                        for candidate in json_obj[LONG_ANSWER_CANDIDATES]\n",
        "                       ],\n",
        "                      ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hugm22sMVtOD",
        "colab_type": "text"
      },
      "source": [
        "### Move these generated csv files to my google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gTvejGEHGIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbd43bab-3dd6-4036-acd8-bd730a2fdb0b"
      },
      "source": [
        "!mv simplified-nq-test.csv drive/My\\ Drive/\n",
        "!mv simplified-nq-train.csv drive/My\\ Drive/"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'simplified-nq-test.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CKOinmsWByl",
        "colab_type": "code",
        "outputId": "b42b248e-b25a-4e3e-8208-9e5480ae4f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "# load training data and check if it's ok\n",
        "simplified_train_csv_path = \"drive/My Drive/simplified-nq-train.csv\"\n",
        "\n",
        "simplified_train_pd = pd.read_csv(simplified_train_csv_path, sep=';', chunksize=1)\n",
        "next(simplified_train_pd)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>long_answer_candidates</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5655493461695504401</td>\n",
              "      <td>which is the most common use of opt-in e-mail ...</td>\n",
              "      <td>['&lt;Table&gt; &lt;Tr&gt; &lt;Td&gt; &lt;/Td&gt; &lt;Td&gt; ( hide ) This a...</td>\n",
              "      <td>{'yes_no_answer': 'NONE', 'long_answer': {'sta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            example_id  ...                                        annotations\n",
              "0  5655493461695504401  ...  {'yes_no_answer': 'NONE', 'long_answer': {'sta...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeolX8NVPcar",
        "colab_type": "code",
        "outputId": "89d63540-8554-4f58-931c-0976365728ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load testing data and check if it's ok\n",
        "simplified_test_csv_path = \"drive/My Drive/simplified-nq-test.csv\"\n",
        "\n",
        "simplified_test_pd = pd.read_csv(simplified_test_csv_path, sep=';')\n",
        "simplified_test_pd.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>long_answer_candidates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1220107454853145579</td>\n",
              "      <td>who is the south african high commissioner in ...</td>\n",
              "      <td>['&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; High Commissio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8777415633185303067</td>\n",
              "      <td>the office episode when they sing to michael</td>\n",
              "      <td>['&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; `` Michael \\'s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4640548859154538040</td>\n",
              "      <td>what is the main idea of the cross of gold speech</td>\n",
              "      <td>['&lt;Table&gt; Cross of Gold speech &lt;Tr&gt; &lt;Td_colspa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-5316095317154496261</td>\n",
              "      <td>when was i want to sing in opera written</td>\n",
              "      <td>['&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; Wilkie Bard &lt;/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8752372642178983917</td>\n",
              "      <td>who does the voices in ice age collision course</td>\n",
              "      <td>['&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; Ice Age : Coll...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            example_id  ...                             long_answer_candidates\n",
              "0 -1220107454853145579  ...  ['<Table> <Tr> <Th_colspan=\"2\"> High Commissio...\n",
              "1  8777415633185303067  ...  ['<Table> <Tr> <Th_colspan=\"2\"> `` Michael \\'s...\n",
              "2  4640548859154538040  ...  ['<Table> Cross of Gold speech <Tr> <Td_colspa...\n",
              "3 -5316095317154496261  ...  ['<Table> <Tr> <Th_colspan=\"2\"> Wilkie Bard </...\n",
              "4 -8752372642178983917  ...  ['<Table> <Tr> <Th_colspan=\"2\"> Ice Age : Coll...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUvno3lZYcSp",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Short Answer Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1AFfkJX5yvS",
        "colab_type": "text"
      },
      "source": [
        "For long answers that exist, there are several cases of short answers:\n",
        "1. YES/NO\n",
        "2. a sentence or phrase\n",
        "3. no short answer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5PYQ3NcYbNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Short_answer_dataset():\n",
        "  def __init__(self, tokenizer, data_path='drive/My Drive/simplified-nq-train.csv', mode='train'):\n",
        "    assert mode in ['train', 'test']\n",
        "    self.df = pd.read_csv(data_path, sep=\";\", chunksize=1)\n",
        "    self.mode = mode\n",
        "    self.tokenizer = tokenizer\n",
        "    self.yes_no_label_map = {'YES': 1, 'NO': 2, 'NONE': 3}\n",
        "    self._next_index = 0\n",
        "\n",
        "\n",
        "  def get_dataset_generator_function(self):\n",
        "    return self._create_data_generator\n",
        "\n",
        "\n",
        "  '''\n",
        "  target_format: 'raw'|'bert'\n",
        "  '''\n",
        "  def _create_data_generator(self, target_format='bert'):\n",
        "    temp_next_index = 0\n",
        "    for instance in self.df:\n",
        "      if temp_next_index == self._next_index:\n",
        "        self._next_index += 1\n",
        "        if target_format == 'bert':\n",
        "          yield self.get_bert_compatible_instance(instance)\n",
        "        else:\n",
        "          yield instance\n",
        "      else:\n",
        "        temp_next_index += 1\n",
        "\n",
        "\n",
        "  '''\n",
        "  make a pair that consists of question text and long answer, then return 3 tensors\n",
        "  for the pair:\n",
        "  - tokens_tensor：tokens list made from concatenating two sentences. special tokens are included([CLS], [SEP], etc.)\n",
        "  - segments_tensor： classify the boundary of each sentence; 0 for the first sentence, 1 for the second sentence\n",
        "  - masks_tensor\n",
        "  - label_tensor： none if it's in testing mode\n",
        "  '''\n",
        "  def get_bert_compatible_instance(self, instance):\n",
        "    '''\n",
        "    helper functions\n",
        "    '''\n",
        "    def _get_question_long_answer_pair(instance):\n",
        "      json_obj = ast.literal_eval(instance[\"annotations\"].iloc[0])\n",
        "      question_text = instance[\"question_text\"].iloc[0]\n",
        "      long_answer_text = json_obj[\"long_answer\"]\n",
        "      return question_text, long_answer_text\n",
        "\n",
        "    def _get_short_answer_label(instance):\n",
        "      json_obj = ast.literal_eval(instance[\"annotations\"].iloc[0])\n",
        "      return json_obj[\"yes_no_answer\"]\n",
        "\n",
        "    ### build label_tensor\n",
        "    if self.mode == 'train':\n",
        "      short_answer_label = _get_short_answer_label(instance)\n",
        "      label_id = self.yes_no_label_map[short_answer_label]\n",
        "      label_tensor = tf.constant(label_id, dtype=tf.int64)\n",
        "    else:\n",
        "      label_tensor = None\n",
        "\n",
        "    # question_text is the first sentence(a)\n",
        "    # long_answer_text is the second sentence(b)\n",
        "    question_text, long_answer_text = _get_question_long_answer_pair(instance)\n",
        "    \n",
        "    print(question_text)\n",
        "    print(long_answer_text)\n",
        "\n",
        "    ### build tokens_tensor\n",
        "    # first sentence\n",
        "    word_pieces = [\"[CLS]\"]\n",
        "    tokens_a = self.tokenizer.tokenize(question_text)\n",
        "    word_pieces += tokens_a + [\"[SEP]\"]\n",
        "    len_a = len(word_pieces)\n",
        "\n",
        "    # second sentence\n",
        "    tokens_b = self.tokenizer.tokenize(long_answer_text)\n",
        "    word_pieces += tokens_b + [\"[SEP]\"]\n",
        "    len_b = len(word_pieces) - len_a\n",
        "\n",
        "    ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "    tokens_tensor = tf.constant(ids, dtype=tf.int64)\n",
        "\n",
        "    ### build segments_tensor\n",
        "    segments_tensor = tf.constant([0] * len_a + [1] * len_b, dtype=tf.int64)\n",
        "\n",
        "    ### build masks_tensor\n",
        "    masks_tensors = tf.zeros(tokens_tensor.shape, dtype=tf.int64)\n",
        "    masks_tensors = tf.where(tokens_tensor != 0 , 1, 0)\n",
        "\n",
        "    return (tokens_tensor, segments_tensor, masks_tensors), label_tensor\n",
        "\n",
        "  \n",
        "  def convert_ids_to_tokens(self, tokens_tensor):\n",
        "    return self.tokenizer.convert_ids_to_tokens(tokens_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clRtbCkozf0_",
        "colab_type": "text"
      },
      "source": [
        "### Initialize BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qBpoxcnzZWp",
        "colab_type": "code",
        "outputId": "315e9bfc-b25a-4cd8-a64f-09d88ffbe68a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "html_tags = ['<P>', '</P>', '<Table>', '</Table>', '<Tr>', '</Tr>', '<Li>', '</Li>', '<Ol>', '</Ol>', '<Dl>', '</Dl>', '<Ul>','</Ul>']\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_basic_tokenize=False)\n",
        "bert_tokenizer.add_tokens(html_tags)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzeH5voph-z9",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8dhWJhjh94J",
        "colab_type": "code",
        "outputId": "5bc6192d-fe75-4fcf-e61e-f0d22bcde0b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "short_answer_train_dataset_gen = Short_answer_dataset(bert_tokenizer).get_dataset_generator_function()\n",
        "data = next(short_answer_train_dataset_gen())\n",
        "#ds_short_answer_train_dataset = tf.data.Dataset.from_generator(\n",
        "#    short_answer_train_dataset_gen, \n",
        "#    output_types=(tf.int64, tf.int64, tf.int64, tf.int64)\n",
        "\n",
        "#for a in ds_short_answer_train_dataset.take(1):\n",
        "#  print(a)\n",
        "\n",
        "#for a in ds_short_answer_train_dataset.padded_batch(10, padded_shapes=([None, None, None, None])).take(10):\n",
        "#  print(a)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "which is the most common use of opt-in e-mail marketing\n",
            "<P> A common example of permission marketing is a newsletter sent to an advertising firm 's customers . Such newsletters inform customers of upcoming events or promotions , or new products . In this type of advertising , a company that wants to send a newsletter to their customers may ask them at the point of purchase if they would like to receive the newsletter . </P>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-410dd230318d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mshort_answer_train_dataset_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShort_answer_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset_generator_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_answer_train_dataset_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#ds_short_answer_train_dataset = tf.data.Dataset.from_generator(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#    short_answer_train_dataset_gen,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-c77fcfabab33>\u001b[0m in \u001b[0;36m_create_data_generator\u001b[0;34m(self, target_format)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bert'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m           \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bert_compatible_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0;32myield\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-c77fcfabab33>\u001b[0m in \u001b[0;36mget_bert_compatible_instance\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m### build masks_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mmasks_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mmasks_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2432\u001b[0m         \u001b[0;31m# Create a constant if it won't be very big. Otherwise create a fill op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m         \u001b[0;31m# to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2434\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2436\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[0;34m(value, shape, dtype, name)\u001b[0m\n\u001b[1;32m   2390\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2392\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2393\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     \u001b[0;31m# Happens when shape is a Tensor, list with Tensor elements, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_eager_identity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_eager_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     raise TypeError(\"Eager execution of tf.constant with unsupported shape \"\n\u001b[1;32m    289\u001b[0m                     \u001b[0;34m\"(value has %d elements, shape is %s with %d elements).\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_eager_fill\u001b[0;34m(dims, value, ctx)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"index_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_INT32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   result, = execute.execute(\n\u001b[0;32m---> 56\u001b[0;31m       b\"Fill\", 1, inputs=inputs_flat, attrs=attrs, ctx=ctx)\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A0MN8aDslkc",
        "colab_type": "text"
      },
      "source": [
        "### Possible Improvements\n",
        "\n",
        "1. Use `jsonlines` package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIAtoE_4lF8D",
        "colab_type": "text"
      },
      "source": [
        "# Short Answer Idenfiticator\n",
        "\n",
        "![short-answer-identificator](https://github.com/cyyeh/kaggle/blob/master/google-qa/short_answer_identificator.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejwRXuwwn27g",
        "colab_type": "text"
      },
      "source": [
        "## Long Answer Encoder\n",
        "\n",
        "see Prepare Short Answer Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvPQV4fkn5Rm",
        "colab_type": "text"
      },
      "source": [
        "## Short Answer Binary Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ9uPnnM69h0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_VazWBfn-zy",
        "colab_type": "text"
      },
      "source": [
        "## Short Answer Null Classifier"
      ]
    }
  ]
}