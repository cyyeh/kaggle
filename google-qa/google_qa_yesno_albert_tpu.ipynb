{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google-qa-yesno-albert-tpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyyeh/kaggle/blob/master/google-qa/google_qa_yesno_albert_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEYxZcKazCWS",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g66cQjyblfno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make sure colab use tf2.x\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsMEk4HoJpbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2NdA7Cqh_74",
        "colab_type": "code",
        "outputId": "6716d207-77ef-4bf8-ff29-b549f53b87a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# install huggingface transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 3.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 54.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from transformers) (1.18.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from transformers) (2.22.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (1.25.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=e7a388a37b807b498c10f061605ce94137f133882088e34add6862ce74bfc29b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QMLgqUq08DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import TFAlbertPreTrainedModel, TFAlbertModel, AlbertConfig\n",
        "from transformers.modeling_tf_utils import get_initializer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZWoy20PzNEL",
        "colab_type": "text"
      },
      "source": [
        "### Setup TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwHs1VJ1JpeT",
        "colab_type": "code",
        "outputId": "3b385d10-e21b-42c6-98d0-dbc0773e86c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "# create tpu resolver and strategy\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.83.87.26:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.83.87.26:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mttn0WDMzPYe",
        "colab_type": "text"
      },
      "source": [
        "### Load Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkyJHIRuY7l9",
        "colab_type": "code",
        "outputId": "8f81dbd4-e330-4322-8b04-d6afa323ab3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_VESswyzURY",
        "colab_type": "code",
        "outputId": "7cf88f02-8bba-4b7f-c1a5-5356aca041da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if os.path.exists('drive/My Drive/yes_no_ans_df.pkl') and \\\n",
        "os.path.exists('drive/My Drive/short_ans_raw_df.pkl'):\n",
        "  print(\"Training dataset is available!\")\n",
        "else:\n",
        "  print(\"Training dataset is not found, please infer the colab notebook below to prepare training data\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset is available!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxEk3D3Fzlda",
        "colab_type": "text"
      },
      "source": [
        "If training dataset is not found, please check this [Colab notebook for preparing training data](https://colab.research.google.com/drive/122bYIInseyFwrRFlTNEGLSNFP594i9OV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-25VgBcLz913",
        "colab_type": "text"
      },
      "source": [
        "Load `short_ans_raw_df.pkl`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jbfJsS0Y97c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "short_ans_raw_df = pd.read_pickle(\"drive/My Drive/short_ans_raw_df.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Nt2ZrC2ygd",
        "colab_type": "code",
        "outputId": "31ff4975-38ef-4719-8675-cc21468b8d68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "short_ans_raw_df = short_ans_raw_df[:80]\n",
        "print(len(short_ans_raw_df))\n",
        "short_ans_raw_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>long_answer_text</th>\n",
              "      <th>yes_no_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5655493461695504401</td>\n",
              "      <td>which is the most common use of opt-in e-mail ...</td>\n",
              "      <td>&lt;P&gt; A common example of permission marketing i...</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5328212470870865242</td>\n",
              "      <td>how i.met your mother who is the mother</td>\n",
              "      <td>&lt;P&gt; Tracy McConnell , better known as `` The M...</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4435104480114867852</td>\n",
              "      <td>what type of fertilisation takes place in humans</td>\n",
              "      <td>&lt;P&gt; The process of fertilization involves a sp...</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5289242154789678439</td>\n",
              "      <td>who had the most wins in the nfl</td>\n",
              "      <td>&lt;P&gt; Active quarterback Tom Brady holds the rec...</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2500044561429484630</td>\n",
              "      <td>who played mantis guardians of the galaxy 2</td>\n",
              "      <td>&lt;P&gt; Pom Klementieff ( born 3 May 1986 ) is a F...</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            example_id  ... yes_no_answer\n",
              "0  5655493461695504401  ...          NONE\n",
              "1  5328212470870865242  ...          NONE\n",
              "2  4435104480114867852  ...          NONE\n",
              "3  5289242154789678439  ...          NONE\n",
              "4 -2500044561429484630  ...          NONE\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoTFBV650DRy",
        "colab_type": "text"
      },
      "source": [
        "Load `yes_no_ans_df.pkl`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPGmld7y0WDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_pickle('drive/My Drive/yes_no_ans_df.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGH3VWU-0cqu",
        "colab_type": "code",
        "outputId": "d0021db1-fd7b-48ef-8211-745a8d3d767f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train_df = train_df[:80]\n",
        "print(len(train_df))\n",
        "train_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label_yes_no</th>\n",
              "      <th>token_ids</th>\n",
              "      <th>segment_ids</th>\n",
              "      <th>mask_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 56, 25, 14, 127, 757, 275, 16, 17034, 8, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 184, 31, 9, 5909, 154, 449, 72, 25, 14, 44...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 98, 1001, 16, 4270, 8005, 4330, 1384, 209,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 72, 41, 14, 127, 4041, 19, 14, 4101, 3, 13...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 72, 257, 169, 3409, 16931, 16, 14, 9358, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label_yes_no  ...                                           mask_ids\n",
              "0             2  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "1             2  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "2             2  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "3             2  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "4             2  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga1ZKeinXM8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b2d7828-ba4f-4a02-a400-08126c4c1c01"
      },
      "source": [
        "tf.one_hot(train_df['label_yes_no'][0], 3)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXR6_Htj0uzq",
        "colab_type": "text"
      },
      "source": [
        "Create distributed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HxCxGU_E3PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def df_to_dataset(dataframe, batch_size, task='classing'):\n",
        "    dataframe = dataframe.copy()\n",
        "    if task == 'classing':\n",
        "      label_yes_no = dataframe.pop('label_yes_no')\n",
        "      dataset = tf.data.Dataset.from_tensor_slices((dict(dataframe), label_yes_no))\n",
        "    elif task == 'squading':\n",
        "      label_start_token = dataframe.pop('label_start_token')\n",
        "      label_end_token = dataframe.pop('label_end_token')\n",
        "      dataset = tf.data.Dataset.from_tensor_slices((dict(dataframe), label_start_token, label_end_token))\n",
        "    \n",
        "    dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHOlqYzHE3Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=16\n",
        "train_ds = df_to_dataset(train_df, batch_size)\n",
        "dist_train_ds = tpu_strategy.experimental_distribute_dataset(train_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjA31ont0-5Y",
        "colab_type": "text"
      },
      "source": [
        "### Create TFAlbertForSequenceClassification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrGylNO5bJTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFAlbertForSequenceClassification(TFAlbertPreTrainedModel):\n",
        "    def __init__(self, config, *inputs, **kwargs):\n",
        "        super(TFAlbertForSequenceClassification, self).__init__(config, *inputs, **kwargs)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.albert = TFAlbertModel(config, name=\"albert\")\n",
        "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = tf.keras.layers.Dense(\n",
        "            config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"classifier\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        outputs = self.albert(inputs, **kwargs)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output, training=kwargs.get(\"training\", False))\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "        return outputs  # logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q46cF6oRfCVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    # input layers\n",
        "    token_ids = keras.Input(shape=(512,), dtype='int32', name='token_ids')\n",
        "    segment_ids = keras.Input(shape=(512,), dtype='int32', name='segment_ids')\n",
        "    mask_ids = keras.Input(shape=(512,), dtype='int32', name='mask_ids')\n",
        "\n",
        "    # bert qa layer\n",
        "    config = AlbertConfig.from_pretrained('albert-base-v2', num_labels=3)\n",
        "    albert_qa_layer = TFAlbertForSequenceClassification(config)\n",
        "\n",
        "    # output layer\n",
        "    albert_qa_outputs = albert_qa_layer([token_ids, mask_ids, segment_ids])\n",
        "    logits = albert_qa_outputs[0]\n",
        "    # create model\n",
        "    model = keras.Model(inputs=[token_ids, mask_ids, segment_ids], outputs=[logits])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQwjT3-S1Quq",
        "colab_type": "text"
      },
      "source": [
        "### TPU Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M259hz7066v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "label_yes_no_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='label_yes_no_train_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ9_7I0Db3wW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tpu custom training loop\n",
        "with tpu_strategy.scope():\n",
        "    model = create_model()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CjYPFbqu2xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(dist_inputs):\n",
        "    # calculate loss and gradient for each replica\n",
        "    def step_fn(inputs):\n",
        "        features, label_yes_no = inputs\n",
        "        one_hot_label = tf.one_hot(label_yes_no, 3)\n",
        "        one_hot_label_index = tf.argmax(one_hot_label, axis=1)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(features)\n",
        "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=one_hot_label_index, logits=logits)\n",
        "            avg_loss = loss / batch_size\n",
        "\n",
        "        gradients = tape.gradient(avg_loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        train_loss(avg_loss)\n",
        "        label_yes_no_train_accuracy(one_hot_label_index, logits)\n",
        "\n",
        "        return avg_loss\n",
        "    \n",
        "    # combine loss for all replicas\n",
        "    per_example_losses = tpu_strategy.experimental_run_v2(step_fn, args=(dist_inputs,))\n",
        "    sum_loss = tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, per_example_losses, axis=0)\n",
        "    return sum_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nPQutj2-6JX",
        "colab_type": "code",
        "outputId": "988943b6-0e77-413a-8b9c-44d8392df54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "  EPOCHS = 10\n",
        "  train_loss.reset_states()\n",
        "  label_yes_no_train_accuracy.reset_states()\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    i = 0\n",
        "    for inputs in dist_train_ds:\n",
        "      train_step(inputs)\n",
        "      i = i + 1\n",
        "      \n",
        "      print(f\"Epoch {epoch} Batch {i}, Loss: {train_loss.result()}, label_yes_no_train_accuracy: {label_yes_no_train_accuracy.result()*100}\")\n",
        "\n",
        "      train_loss.reset_states()\n",
        "      label_yes_no_train_accuracy.reset_states()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 1, Loss: 0.09206603467464447, label_yes_no_train_accuracy: 0.0\n",
            "Epoch 0 Batch 2, Loss: 0.043868012726306915, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 0 Batch 3, Loss: 0.020408928394317627, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 0 Batch 4, Loss: 0.010547973215579987, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 0 Batch 5, Loss: 0.006406833417713642, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 1 Batch 1, Loss: 0.004531951621174812, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 1 Batch 2, Loss: 0.003284827573224902, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 1 Batch 3, Loss: 0.0025544294621795416, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 1 Batch 4, Loss: 0.002187750767916441, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 1 Batch 5, Loss: 0.0020634301472455263, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 2 Batch 1, Loss: 0.001992674544453621, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 2 Batch 2, Loss: 0.13394922018051147, label_yes_no_train_accuracy: 50.0\n",
            "Epoch 2 Batch 3, Loss: 0.1295696496963501, label_yes_no_train_accuracy: 50.0\n",
            "Epoch 2 Batch 4, Loss: 0.002273309277370572, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 2 Batch 5, Loss: 0.002425240818411112, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 3 Batch 1, Loss: 0.002479410031810403, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 3 Batch 2, Loss: 0.002606115071102977, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 3 Batch 3, Loss: 0.0027700779028236866, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 3 Batch 4, Loss: 0.0027025695890188217, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 3 Batch 5, Loss: 0.0028241854161024094, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 4 Batch 1, Loss: 0.002879025414586067, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 4 Batch 2, Loss: 0.0028738691471517086, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 4 Batch 3, Loss: 0.002890609670430422, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 4 Batch 4, Loss: 0.002801333088427782, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 4 Batch 5, Loss: 0.002942122984677553, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 5 Batch 1, Loss: 0.13157247006893158, label_yes_no_train_accuracy: 50.0\n",
            "Epoch 5 Batch 2, Loss: 0.002438791561871767, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 5 Batch 3, Loss: 0.0025581219233572483, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 5 Batch 4, Loss: 0.002506799064576626, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 5 Batch 5, Loss: 0.0023951183538883924, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 6 Batch 1, Loss: 0.002292720600962639, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 6 Batch 2, Loss: 0.0019687782041728497, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 6 Batch 3, Loss: 0.1219065934419632, label_yes_no_train_accuracy: 50.0\n",
            "Epoch 6 Batch 4, Loss: 0.001998462248593569, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 6 Batch 5, Loss: 0.0020286613143980503, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 7 Batch 1, Loss: 0.0019626652356237173, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 7 Batch 2, Loss: 0.0019077135948464274, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 7 Batch 3, Loss: 0.001975483261048794, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 7 Batch 4, Loss: 0.12066999077796936, label_yes_no_train_accuracy: 50.0\n",
            "Epoch 7 Batch 5, Loss: 0.0018138685263693333, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 8 Batch 1, Loss: 0.0018908458296209574, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 8 Batch 2, Loss: 0.002246647607535124, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 8 Batch 3, Loss: 0.09870455414056778, label_yes_no_train_accuracy: 50.0\n",
            "Epoch 8 Batch 4, Loss: 0.0035657864063978195, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 8 Batch 5, Loss: 0.003807198954746127, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 9 Batch 1, Loss: 0.004225471522659063, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 9 Batch 2, Loss: 0.09714582562446594, label_yes_no_train_accuracy: 50.0\n",
            "Epoch 9 Batch 3, Loss: 0.0031380322761833668, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 9 Batch 4, Loss: 0.005820415914058685, label_yes_no_train_accuracy: 100.0\n",
            "Epoch 9 Batch 5, Loss: 0.0021831104531884193, label_yes_no_train_accuracy: 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG1igqzU_h-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}