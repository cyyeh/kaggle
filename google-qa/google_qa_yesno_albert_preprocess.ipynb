{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google-qa-yesno-albert-preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyyeh/kaggle/blob/master/google-qa/google_qa_yesno_albert_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKOHe0p-Ht5R",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onr7kcYyH0Yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWrB_OZ5Hyvw",
        "colab_type": "code",
        "outputId": "761e330d-227d-4c32-ba7b-e6ac0f149313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!pip install transformers # BertModel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\r\u001b[K     |▊                               | 10kB 25.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 6.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 71kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 122kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 143kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 153kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 174kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 184kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 204kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 215kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 225kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 235kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 245kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 256kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 266kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 276kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 286kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 296kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 307kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 317kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 327kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 337kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 348kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 358kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 368kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 378kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 389kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 399kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 409kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 419kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 430kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 440kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 450kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 460kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 471kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 44.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=7f3bebf47ed6d3a091c92390cfd9f4a712785b4c17c8ce7e483c483cd3baf792\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBWIdGEBhzs-",
        "colab_type": "text"
      },
      "source": [
        "### Install cuDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxpg9MQJhwOH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "f2ae8929-3786-4a37-80de-3897818ce672"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Feb 17 14:23:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCWLqORJiGIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7244f693-6ed3-4553-c08b-094cb20eebd6"
      },
      "source": [
        "!nvcc -V"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8fqGRQ9iIin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "b7ff923b-73db-43e1-e3a6-1eb46ad90845"
      },
      "source": [
        "!pip install cudf-cuda100"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cudf-cuda100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/a5/a40e0e0290c332cb2c27dd824c3e8f242d56af27cfdb4da92e5ebe0cf076/cudf_cuda100-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (17.2MB)\n",
            "\u001b[K     |████████████████████████████████| 17.2MB 197kB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser==2.19 in /usr/local/lib/python3.6/dist-packages (from cudf-cuda100) (2.19)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from cudf-cuda100) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from cudf-cuda100) (1.17.5)\n",
            "Collecting pyarrow==0.12.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/37/eb9aefcd6a041dffb4db6729daea2a91a01a1bf9815e02a3d35281348a85/pyarrow-0.12.1-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4MB 36.3MB/s \n",
            "\u001b[?25hCollecting numba<0.42,>=0.40.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/55/938f0023a4f37fe24460d46846670aba8170a6b736f1693293e710d4a6d0/numba-0.41.0-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython<0.30,>=0.29 in /usr/local/lib/python3.6/dist-packages (from cudf-cuda100) (0.29.15)\n",
            "Collecting nvstrings-cuda100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/88/5cddf81ffc06908d1cba1dca357e3eb1dab050f46881752fdb4084eb1484/nvstrings_cuda100-0.3.0.post1-cp36-cp36m-manylinux1_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.6/dist-packages (from cudf-cuda100) (0.25.3)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.12.1->cudf-cuda100) (1.12.0)\n",
            "Requirement already satisfied: llvmlite>=0.26.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba<0.42,>=0.40.0->cudf-cuda100) (0.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->cudf-cuda100) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->cudf-cuda100) (2018.9)\n",
            "Installing collected packages: pyarrow, numba, nvstrings-cuda100, cudf-cuda100\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "  Found existing installation: numba 0.47.0\n",
            "    Uninstalling numba-0.47.0:\n",
            "      Successfully uninstalled numba-0.47.0\n",
            "Successfully installed cudf-cuda100-0.6.1 numba-0.41.0 nvstrings-cuda100-0.3.0.post1 pyarrow-0.12.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUuzSetpiNp4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8ea3c66-585d-40fc-9e7c-bd1e87451448"
      },
      "source": [
        "!find / -name librmm.so*"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/librmm.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqrWXPcUiTUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /usr/local/lib/python3.6/dist-packages/librmm.so ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1chFpuLeiZkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['NUMBAPRO_NVVM']='/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE']='/usr/local/cuda-10.0/nvvm/libdevice'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Gl3AbLioC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nvstrings, nvcategory, cudf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSYR9qivH3cE",
        "colab_type": "text"
      },
      "source": [
        "# Prepare YES/NO Answer Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGlXk3heH5um",
        "colab_type": "code",
        "outputId": "65696b58-57ad-4933-9cbe-cff1950d0829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E4qELtHIHGL",
        "colab_type": "text"
      },
      "source": [
        "Check if training/testing dataset is available in your google drive. If it's not available, you should run code inside the \"Prepare Kaggle Dataset\" section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8_Ex5YQIDNo",
        "colab_type": "code",
        "outputId": "5eec88b0-db62-4e3b-ee7e-f16186bd33fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if os.path.exists('drive/My Drive/yes_no_ans_df.pkl') and \\\n",
        "os.path.exists('drive/My Drive/short_ans_raw_df.pkl'):\n",
        "  print(\"Training dataset is available!\")\n",
        "else:\n",
        "  print(\"Training dataset is not found, please run code inside the 'Prepare Kaggle Dataset' section.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset is available!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciW0IPzaIO1I",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Kaggle Dataset for [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QowWvieAIRDR",
        "colab_type": "text"
      },
      "source": [
        "### Download Question Answering Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUOkqK_tISun",
        "colab_type": "code",
        "outputId": "39ecf8cd-f4c3-4fa2-8df9-182890a4152f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"chihyuyeh\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"f21b340fc8082977cbf954c80ad69ae1\" # key from the json file\n",
        "!kaggle competitions download -c tensorflow2-question-answering"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading simplified-nq-test.jsonl.zip to /content\n",
            "100% 4.78M/4.78M [00:00<00:00, 25.2MB/s]\n",
            "\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/18.2k [00:00<?, ?B/s]\n",
            "100% 18.2k/18.2k [00:00<00:00, 17.7MB/s]\n",
            "Downloading simplified-nq-train.jsonl.zip to /content\n",
            "100% 4.45G/4.46G [01:30<00:00, 61.3MB/s]\n",
            "100% 4.46G/4.46G [01:30<00:00, 52.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHZnsqknn99x",
        "colab_type": "code",
        "outputId": "01b5e2ed-fc6f-4bde-bc1d-acc5a371a10e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip simplified-nq-train.jsonl.zip\n",
        "!unzip simplified-nq-test.jsonl.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  simplified-nq-train.jsonl.zip\n",
            "  inflating: simplified-nq-train.jsonl  \n",
            "Archive:  simplified-nq-test.jsonl.zip\n",
            "  inflating: simplified-nq-test.jsonl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hv1uHLsBPfs",
        "colab_type": "text"
      },
      "source": [
        "### Generate Short Answer Raw Data Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ9gMqFtIbby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = 'simplified-nq-train.jsonl'\n",
        "test_path = 'simplified-nq-test.jsonl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBDNb--Tn49q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extracting_text_using_start_end_token_id(document_text, start_token, end_token):\n",
        "    splitted_document_text = document_text.split()\n",
        "    return ' '.join(splitted_document_text[start_token:end_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH50Z7gin7-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def has_long_answer(long_answer_candidate):\n",
        "  return long_answer_candidate['start_token'] != -1 \\\n",
        "  and long_answer_candidate['candidate_index'] != -1 \\\n",
        "  and long_answer_candidate['end_token'] != -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaXuSGr7BL9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_cleaning_for_short_answer(\n",
        "  json_obj,\n",
        "  task='both',\n",
        "  example_id=True):\n",
        "  '''\n",
        "  keys of the output dictionary: \n",
        "    'example_id' # optional \n",
        "    'question_text'\n",
        "    'long_answer_text'\n",
        "    'yes_no_answer' # exist only if task == 'both' or 'classing'\n",
        "    'short_answer_start_token' # exist only  if task == 'both' or 'squading'\n",
        "    'short_answer_end_token' # exist only if task == 'both' or 'squading'\n",
        "  ''' \n",
        "  assert task == 'classing' or task == 'squading' or task == 'both'\n",
        "  new_data_d = {}\n",
        "  # assignment for both tasks  \n",
        "  annotations = json_obj['annotations'][0]\n",
        "  long_answer_candidate = annotations['long_answer']\n",
        "  if example_id:\n",
        "    new_data_d['example_id'] = json_obj['example_id']\n",
        "  new_data_d['question_text'] = json_obj['question_text']\n",
        "  long_ans_start = long_answer_candidate['start_token']\n",
        "  long_ans_end = long_answer_candidate['end_token']\n",
        "  new_data_d['long_answer_text'] = (\n",
        "    extracting_text_using_start_end_token_id(\n",
        "      json_obj['document_text'],\n",
        "      long_ans_start,\n",
        "      long_ans_end\n",
        "    ))\n",
        "  if task != 'both':\n",
        "    if task == 'squading':\n",
        "      short_answer_candidate = annotations['short_answers']\n",
        "      if not short_answer_candidate:\n",
        "        short_ans_start = -1\n",
        "        short_ans_end = -1\n",
        "      else:\n",
        "        short_ans_start = short_answer_candidate[0]['start_token'] - long_ans_start\n",
        "        short_ans_end = short_answer_candidate[0]['end_token'] - long_ans_start\n",
        "      new_data_d['short_answer_start_token'] = short_ans_start\n",
        "      new_data_d['short_answer_end_token'] = short_ans_end\n",
        "    elif task == 'classing':\n",
        "      new_data_d['yes_no_answer'] = annotations['yes_no_answer']\n",
        "  else:\n",
        "    # get squading labels \n",
        "    short_answer_candidate = annotations['short_answers']\n",
        "    if not short_answer_candidate:\n",
        "      short_ans_start = -1\n",
        "      short_ans_end = -1\n",
        "    else:\n",
        "      short_ans_start = short_answer_candidate[0]['start_token'] - long_ans_start\n",
        "      short_ans_end = short_answer_candidate[0]['end_token'] - long_ans_start\n",
        "    new_data_d['short_answer_start_token'] = short_ans_start\n",
        "    new_data_d['short_answer_end_token'] = short_ans_end\n",
        "    # get classing labels \n",
        "    new_data_d['yes_no_answer'] = annotations['yes_no_answer']\n",
        "  return new_data_d "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_msdHUPaR58R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_short_answer_dataset(path):\n",
        "  short_answer_dataset = []\n",
        "  with open(path) as f:\n",
        "    for line in f:\n",
        "      old_data_d = json.loads(line)\n",
        "      if has_long_answer(old_data_d['annotations'][0]['long_answer']):\n",
        "        new_data_d = data_cleaning_for_short_answer(old_data_d)\n",
        "        short_answer_dataset.append(new_data_d)\n",
        "  return df.DataFrame(short_answer_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I57a4LEhIbej",
        "colab_type": "code",
        "outputId": "37f1d8e1-9d25-43ca-cd59-afae94cd8390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "raw_df = create_short_answer_dataset(train_path)\n",
        "\n",
        "print(len(raw_df))\n",
        "raw_df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-5a9f0b5c2446>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-n1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'create_short_answer_dataset(train_path)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1060\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d81b13d47f1d>\u001b[0m in \u001b[0;36mcreate_short_answer_dataset\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnew_data_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_cleaning_for_short_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_data_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mshort_answer_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_answer_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cudf/dataframe/dataframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_series, index)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mname_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforceindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTNxPQ49sVoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(raw_df))\n",
        "raw_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNl7RdMIKQIJ",
        "colab_type": "text"
      },
      "source": [
        "### Save Short Answer Dataset to Pickle Format and Export It To Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D3Y9eulKPeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_df.to_pickle(\"./short_ans_raw_df.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5SzPpxgKkQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp ./short_ans_raw_df.pkl /content/drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O4zpkqVBe6-",
        "colab_type": "text"
      },
      "source": [
        "### Create YES/NO Answer Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o2tJ0TMaa1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_short_ans_features(raw_df, mode='1'):\n",
        "  '''\n",
        "  parameters:\n",
        "  raw_df: short answer dataframe\n",
        "  mode: 1(default): yes/no answer; 2: short answer entity\n",
        "  returns:\n",
        "  dataframe for tokenizedshort answer dataset\n",
        "  '''\n",
        "  from transformers import AlbertTokenizer\n",
        "\n",
        "  tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
        "  short_ans_features_dict = {\n",
        "    'token_ids': [],\n",
        "    'segment_ids': [],\n",
        "    'mask_ids': []\n",
        "  }\n",
        "\n",
        "  if mode == '1':\n",
        "    short_ans_features_dict['label_yes_no'] = []\n",
        "  elif mode == '2':\n",
        "    short_ans_features_dict['label_start_tokens'] = []\n",
        "    short_ans_features_dict['label_end_tokens'] = []\n",
        "\n",
        "  label_yes_no_map = {\n",
        "    'YES': 0,\n",
        "    'NO': 1,\n",
        "    'NONE': 2\n",
        "  }\n",
        "\n",
        "  MAX_LENGTH = 512\n",
        "\n",
        "  for _, row in raw_df.iterrows():\n",
        "    # tokenize question text\n",
        "    tokens = ['[CLS]'] + tokenizer.tokenize(row['question_text']) + ['[SEP]']\n",
        "    sentence_A_len = len(tokens)\n",
        "  \n",
        "    # tokenize no long answer\n",
        "    if row['short_answer_start_token'] == -1:\n",
        "      tokens = tokens + tokenizer.tokenize(row['long_answer_text']) + ['[SEP]']\n",
        "      sentence_len = len(tokens)\n",
        "      label_start_token = 0\n",
        "      label_end_token = 0\n",
        "    # tokenize short answer span\n",
        "    else:\n",
        "      # cut long answer into 3 chunks\n",
        "      long_answer = row['long_answer_text'].split()\n",
        "      chunk_1 = ' '.join(long_answer[:row['short_answer_start_token']])\n",
        "      chunk_2 = ' '.join(long_answer[row['short_answer_start_token']:row['short_answer_end_token']])\n",
        "      chunk_3 = ' '.join(long_answer[row['short_answer_end_token']:])\n",
        "\n",
        "      # handle new start end token\n",
        "      tokens = tokens + tokenizer.tokenize(chunk_1)\n",
        "      label_start_token = len(tokens)\n",
        "      tokens = tokens + tokenizer.tokenize(chunk_2)\n",
        "      label_end_token = len(tokens)\n",
        "\n",
        "      tokens = tokens + tokenizer.tokenize(chunk_3) + ['[SEP]']\n",
        "      sentence_len = len(tokens)\n",
        "\n",
        "    # apply truncating\n",
        "    if sentence_len > MAX_LENGTH:\n",
        "      tokens = tokens[:MAX_LENGTH-1] + ['[SEP]']\n",
        "      sentence_len = MAX_LENGTH\n",
        "    if label_end_token > MAX_LENGTH - 1: # should not exceed last token [SEP]\n",
        "      label_start_token = 0\n",
        "      label_end_token = 0\n",
        "\n",
        "    # create segment_id and mask_id\n",
        "    segment_ids = sentence_A_len * [0] + (sentence_len - sentence_A_len) * [1] \n",
        "    mask_ids = sentence_len * [1]\n",
        "\n",
        "    # apply padding\n",
        "    if (sentence_len < MAX_LENGTH):\n",
        "      pad_len = MAX_LENGTH - sentence_len\n",
        "      tokens = tokens + pad_len * ['[PAD]']\n",
        "      segment_ids = segment_ids + pad_len * [0]\n",
        "      mask_ids = mask_ids + pad_len * [0]\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # yes_no_label\n",
        "    yes_no_label = label_yes_no_map[row['yes_no_answer']]\n",
        "\n",
        "    # append to lists\n",
        "    short_ans_features_dict['token_ids'].append(token_ids)\n",
        "    short_ans_features_dict['segment_ids'].append(segment_ids)\n",
        "    short_ans_features_dict['mask_ids'].append(mask_ids)\n",
        "    if mode == '1':\n",
        "      short_ans_features_dict['label_yes_no'].append(yes_no_label)\n",
        "    elif mode == '2':\n",
        "      short_ans_features_dict['label_start_tokens'].append(label_start_token)\n",
        "      short_ans_features_dict['label_end_tokens'].append(label_end_token)\n",
        "\n",
        "  return pd.DataFrame(short_ans_features_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F3D4uFw9EwO",
        "colab_type": "code",
        "outputId": "b4c789e0-99d5-4933-c7c3-cf7c6f39dbe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "yes_no_ans_df = create_short_ans_features(raw_df)\n",
        "print(len(yes_no_ans_df))\n",
        "yes_no_ans_df.head()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_ids</th>\n",
              "      <th>segment_ids</th>\n",
              "      <th>mask_ids</th>\n",
              "      <th>label_yes_no</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[2, 56, 25, 14, 127, 757, 275, 16, 17034, 8, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2, 184, 31, 9, 5909, 154, 449, 72, 25, 14, 44...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[2, 98, 1001, 16, 4270, 8005, 4330, 1384, 209,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2, 72, 41, 14, 127, 4041, 19, 14, 4101, 3, 13...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2, 72, 257, 169, 3409, 16931, 16, 14, 9358, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           token_ids  ... label_yes_no\n",
              "0  [2, 56, 25, 14, 127, 757, 275, 16, 17034, 8, 1...  ...            2\n",
              "1  [2, 184, 31, 9, 5909, 154, 449, 72, 25, 14, 44...  ...            2\n",
              "2  [2, 98, 1001, 16, 4270, 8005, 4330, 1384, 209,...  ...            2\n",
              "3  [2, 72, 41, 14, 127, 4041, 19, 14, 4101, 3, 13...  ...            2\n",
              "4  [2, 72, 257, 169, 3409, 16931, 16, 14, 9358, 1...  ...            2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CoUsHxVBoDQ",
        "colab_type": "text"
      },
      "source": [
        "### Save YES/NO Answer Dataset to Pickle Format and Export It To Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj1gSOK06W1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save dataframe to pickle file\n",
        "yes_no_ans_df.to_pickle(\"./yes_no_ans_df.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ob60ZPqk23w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp ./yes_no_ans_df.pkl /content/drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCzPNunznK71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axlGejzRaKPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}