{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google-qa-yesno-albert-preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyyeh/kaggle/blob/master/google-qa/google_qa_yesno_albert_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKOHe0p-Ht5R",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWrB_OZ5Hyvw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "1f7cb6b2-3b84-4a45-f584-a5a86f11459d"
      },
      "source": [
        "!pip install transformers # BertModel"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from transformers) (1.18.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from transformers) (2.22.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (1.25.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onr7kcYyH0Yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSYR9qivH3cE",
        "colab_type": "text"
      },
      "source": [
        "# Prepare YES/NO Answer Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGlXk3heH5um",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "bd29211e-0bf3-4418-cf6c-a0e842f529c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E4qELtHIHGL",
        "colab_type": "text"
      },
      "source": [
        "Check if training/testing dataset is available in your google drive. If it's not available, you should run code inside the \"Prepare Kaggle Dataset\" section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8_Ex5YQIDNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5eec88b0-db62-4e3b-ee7e-f16186bd33fe"
      },
      "source": [
        "if os.path.exists('drive/My Drive/yes_no_ans_df.pkl') and \\\n",
        "os.path.exists('drive/My Drive/short_ans_raw_df.pkl'):\n",
        "  print(\"Training dataset is available!\")\n",
        "else:\n",
        "  print(\"Training dataset is not found, please run code inside the 'Prepare Kaggle Dataset' section.\")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset is available!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciW0IPzaIO1I",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Kaggle Dataset for [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QowWvieAIRDR",
        "colab_type": "text"
      },
      "source": [
        "### Download Question Answering Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUOkqK_tISun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1cb36353-d250-4045-e736-00542323f4ea"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"chihyuyeh\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"f21b340fc8082977cbf954c80ad69ae1\" # key from the json file\n",
        "!kaggle competitions download -c tensorflow2-question-answering"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading simplified-nq-test.jsonl.zip to /content\n",
            "100% 4.78M/4.78M [00:00<00:00, 49.6MB/s]\n",
            "\n",
            "Downloading simplified-nq-train.jsonl.zip to /content\n",
            "100% 4.46G/4.46G [00:58<00:00, 65.2MB/s]\n",
            "100% 4.46G/4.46G [00:58<00:00, 82.0MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/18.2k [00:00<?, ?B/s]\n",
            "100% 18.2k/18.2k [00:00<00:00, 15.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHZnsqknn99x",
        "colab_type": "code",
        "outputId": "de0dd8e3-51e0-4818-f0e5-4dd813604eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip simplified-nq-train.jsonl.zip\n",
        "!unzip simplified-nq-test.jsonl.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  simplified-nq-train.jsonl.zip\n",
            "  inflating: simplified-nq-train.jsonl  \n",
            "Archive:  simplified-nq-test.jsonl.zip\n",
            "  inflating: simplified-nq-test.jsonl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hv1uHLsBPfs",
        "colab_type": "text"
      },
      "source": [
        "### Generate Short Answer Raw Data Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ9gMqFtIbby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = 'simplified-nq-train.jsonl'\n",
        "test_path = 'simplified-nq-test.jsonl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBDNb--Tn49q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extracting_text_using_start_end_token_id(document_text, start_token, end_token):\n",
        "    splitted_document_text = document_text.split()\n",
        "    return ' '.join(splitted_document_text[start_token:end_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH50Z7gin7-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def has_long_answer(long_answer_candidate):\n",
        "  return long_answer_candidate['start_token'] != -1 \\\n",
        "  and long_answer_candidate['candidate_index'] != -1 \\\n",
        "  and long_answer_candidate['end_token'] != -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaXuSGr7BL9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_cleaning_for_short_answer(json_obj):\n",
        "  annotations = json_obj['annotations'][0]\n",
        "  long_answer_candidate = annotations['long_answer']\n",
        "  long_ans_start = long_answer_candidate['start_token']\n",
        "  long_ans_end = long_answer_candidate['end_token']\n",
        "  short_answer_candidate = annotations['short_answers']\n",
        "\n",
        "  if not short_answer_candidate:\n",
        "    short_ans_start = -1\n",
        "    short_ans_end = -1\n",
        "  else:\n",
        "    short_ans_start = short_answer_candidate[0]['start_token'] - long_ans_start\n",
        "    short_ans_end = short_answer_candidate[0]['end_token'] - long_ans_start\n",
        "\n",
        "  new_data_d = {\n",
        "        'example_id': json_obj['example_id'],\n",
        "        'question_text': json_obj['question_text'],\n",
        "        'long_answer_text': extracting_text_using_start_end_token_id(\n",
        "            json_obj['document_text'],\n",
        "            long_ans_start,\n",
        "            long_ans_end\n",
        "        ),\n",
        "        'yes_no_answer': annotations['yes_no_answer'],\n",
        "        'short_answer_start_token': short_ans_start,\n",
        "        'short_answer_end_token': short_ans_end\n",
        "  }\n",
        "  return new_data_d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_msdHUPaR58R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_short_answer_dataset(path):\n",
        "  short_answer_dataset = []\n",
        "  with open(path) as f:\n",
        "    for line in f:\n",
        "      old_data_d = json.loads(line)\n",
        "      if has_long_answer(old_data_d['annotations'][0]['long_answer']):\n",
        "        new_data_d = data_cleaning_for_short_answer(old_data_d)\n",
        "        short_answer_dataset.append(new_data_d)\n",
        "  return pd.DataFrame(short_answer_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I57a4LEhIbej",
        "colab_type": "code",
        "outputId": "01ef3272-27ab-4db6-e77c-ac8b8768a113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "raw_df = create_short_answer_dataset(train_path)\n",
        "\n",
        "print(len(raw_df))\n",
        "raw_df.head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>long_answer_text</th>\n",
              "      <th>yes_no_answer</th>\n",
              "      <th>short_answer_start_token</th>\n",
              "      <th>short_answer_end_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5655493461695504401</td>\n",
              "      <td>which is the most common use of opt-in e-mail ...</td>\n",
              "      <td>&lt;P&gt; A common example of permission marketing i...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5328212470870865242</td>\n",
              "      <td>how i.met your mother who is the mother</td>\n",
              "      <td>&lt;P&gt; Tracy McConnell , better known as `` The M...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4435104480114867852</td>\n",
              "      <td>what type of fertilisation takes place in humans</td>\n",
              "      <td>&lt;P&gt; The process of fertilization involves a sp...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5289242154789678439</td>\n",
              "      <td>who had the most wins in the nfl</td>\n",
              "      <td>&lt;P&gt; Active quarterback Tom Brady holds the rec...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2500044561429484630</td>\n",
              "      <td>who played mantis guardians of the galaxy 2</td>\n",
              "      <td>&lt;P&gt; Pom Klementieff ( born 3 May 1986 ) is a F...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            example_id  ... short_answer_end_token\n",
              "0  5655493461695504401  ...                     17\n",
              "1  5328212470870865242  ...                      3\n",
              "2  4435104480114867852  ...                     -1\n",
              "3  5289242154789678439  ...                      5\n",
              "4 -2500044561429484630  ...                      3\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNl7RdMIKQIJ",
        "colab_type": "text"
      },
      "source": [
        "### Save Short Answer Dataset to Pickle Format and Export It To Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D3Y9eulKPeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_df.to_pickle(\"./short_ans_raw_df.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5SzPpxgKkQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp ./short_ans_raw_df.pkl /content/drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O4zpkqVBe6-",
        "colab_type": "text"
      },
      "source": [
        "### Create YES/NO Answer Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o2tJ0TMaa1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_short_ans_features(raw_df, mode='1'):\n",
        "  '''\n",
        "  parameters:\n",
        "  raw_df: short answer dataframe\n",
        "  mode: 1(default): yes/no answer; 2: short answer entity\n",
        "  returns:\n",
        "  dataframe for tokenizedshort answer dataset\n",
        "  '''\n",
        "  from transformers import AlbertTokenizer\n",
        "\n",
        "  tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
        "  short_ans_features_dict = {\n",
        "    'token_ids': [],\n",
        "    'segment_ids': [],\n",
        "    'mask_ids': []\n",
        "  }\n",
        "\n",
        "  if mode == '1':\n",
        "    short_ans_features_dict['label_yes_no'] = []\n",
        "  elif mode == '2':\n",
        "    short_ans_features_dict['label_start_tokens'] = []\n",
        "    short_ans_features_dict['label_end_tokens'] = []\n",
        "\n",
        "  label_yes_no_map = {\n",
        "    'YES': 0,\n",
        "    'NO': 1,\n",
        "    'NONE': 2\n",
        "  }\n",
        "\n",
        "  MAX_LENGTH = 512\n",
        "\n",
        "  for i in range(len(raw_df)):\n",
        "    # tokenize question text\n",
        "    tokens = ['[CLS]'] + tokenizer.tokenize(raw_df.question_text[i]) + ['[SEP]']\n",
        "    sentence_A_len = len(tokens)\n",
        "  \n",
        "    # tokenize no long answer\n",
        "    if raw_df.short_answer_start_token[i] == -1:\n",
        "      tokens = tokens + tokenizer.tokenize(raw_df.long_answer_text[i]) + ['[SEP]']\n",
        "      sentence_len = len(tokens)\n",
        "      label_start_token = 0\n",
        "      label_end_token = 0\n",
        "    # tokenize short answer span\n",
        "    else:\n",
        "      # cut long answer into 3 chunks\n",
        "      long_answer = raw_df.long_answer_text[i].split()\n",
        "      chunk_1 = ' '.join(long_answer[:raw_df.short_answer_start_token[i]])\n",
        "      chunk_2 = ' '.join(long_answer[raw_df.short_answer_start_token[i]:raw_df.short_answer_end_token[i]])\n",
        "      chunk_3 = ' '.join(long_answer[raw_df.short_answer_end_token[i]:])\n",
        "\n",
        "      # handle new start end token\n",
        "      tokens = tokens + tokenizer.tokenize(chunk_1)\n",
        "      label_start_token = len(tokens)\n",
        "      tokens = tokens + tokenizer.tokenize(chunk_2)\n",
        "      label_end_token = len(tokens)\n",
        "\n",
        "      tokens = tokens + tokenizer.tokenize(chunk_3) + ['[SEP]']\n",
        "      sentence_len = len(tokens)\n",
        "\n",
        "    # apply truncating\n",
        "    if sentence_len > MAX_LENGTH:\n",
        "      tokens = tokens[:MAX_LENGTH-1] + ['[SEP]']\n",
        "      sentence_len = MAX_LENGTH\n",
        "    if label_end_token > MAX_LENGTH - 1: # should not exceed last token [SEP]\n",
        "      label_start_token = 0\n",
        "      label_end_token = 0\n",
        "\n",
        "    # create segment_id and mask_id\n",
        "    segment_ids = sentence_A_len * [0] + (sentence_len - sentence_A_len) * [1] \n",
        "    mask_ids = sentence_len * [1]\n",
        "\n",
        "    # apply padding\n",
        "    if (sentence_len < MAX_LENGTH):\n",
        "      pad_len = MAX_LENGTH - sentence_len\n",
        "      tokens = tokens + pad_len * ['[PAD]']\n",
        "      segment_ids = segment_ids + pad_len * [0]\n",
        "      mask_ids = mask_ids + pad_len * [0]\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # yes_no_label\n",
        "    yes_no_label = label_yes_no_map[raw_df.yes_no_answer[i]]\n",
        "\n",
        "    # append to lists\n",
        "    short_ans_features_dict['token_ids'].append(token_ids)\n",
        "    short_ans_features_dict['segment_ids'].append(segment_ids)\n",
        "    short_ans_features_dict['mask_ids'].append(mask_ids)\n",
        "    if mode == '1':\n",
        "      short_ans_features_dict['label_yes_no'].append(yes_no_label)\n",
        "    elif mode == '2':\n",
        "      short_ans_features_dict['label_start_tokens'].append(label_start_token)\n",
        "      short_ans_features_dict['label_end_tokens'].append(label_end_token)\n",
        "\n",
        "  return pd.DataFrame(short_ans_features_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F3D4uFw9EwO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8f3e4dc0-70ba-4581-e49a-9b85b944aebf"
      },
      "source": [
        "yes_no_ans_df = create_short_ans_features(raw_df)\n",
        "print(len(yes_no_ans_df))\n",
        "yes_no_ans_df.head()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_ids</th>\n",
              "      <th>segment_ids</th>\n",
              "      <th>mask_ids</th>\n",
              "      <th>label_yes_no</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[2, 56, 25, 14, 127, 757, 275, 16, 17034, 8, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2, 184, 31, 9, 5909, 154, 449, 72, 25, 14, 44...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[2, 98, 1001, 16, 4270, 8005, 4330, 1384, 209,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2, 72, 41, 14, 127, 4041, 19, 14, 4101, 3, 13...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2, 72, 257, 169, 3409, 16931, 16, 14, 9358, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           token_ids  ... label_yes_no\n",
              "0  [2, 56, 25, 14, 127, 757, 275, 16, 17034, 8, 1...  ...            2\n",
              "1  [2, 184, 31, 9, 5909, 154, 449, 72, 25, 14, 44...  ...            2\n",
              "2  [2, 98, 1001, 16, 4270, 8005, 4330, 1384, 209,...  ...            2\n",
              "3  [2, 72, 41, 14, 127, 4041, 19, 14, 4101, 3, 13...  ...            2\n",
              "4  [2, 72, 257, 169, 3409, 16931, 16, 14, 9358, 1...  ...            2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CoUsHxVBoDQ",
        "colab_type": "text"
      },
      "source": [
        "### Save YES/NO Answer Dataset to Pickle Format and Export It To Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj1gSOK06W1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save dataframe to pickle file\n",
        "yes_no_ans_df.to_pickle(\"./yes_no_ans_df.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ob60ZPqk23w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp ./yes_no_ans_df.pkl /content/drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCzPNunznK71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQLU2uH0nLAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}