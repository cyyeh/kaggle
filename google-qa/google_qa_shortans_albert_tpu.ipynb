{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google-qa-shortans-albert-tpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyyeh/kaggle/blob/master/google-qa/google_qa_shortans_albert_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCz27jWFozEp",
        "colab_type": "text"
      },
      "source": [
        "# TPU Training for NQA Short Answers\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEYxZcKazCWS",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g66cQjyblfno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make sure colab use tf2.x\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsMEk4HoJpbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2NdA7Cqh_74",
        "colab_type": "code",
        "outputId": "243edf49-8f40-4674-b024-8352a704b8c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# install huggingface transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from transformers) (2.22.0)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from transformers) (1.18.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QMLgqUq08DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import TFAlbertPreTrainedModel, TFAlbertModel, AlbertConfig\n",
        "from transformers.modeling_tf_utils import get_initializer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZWoy20PzNEL",
        "colab_type": "text"
      },
      "source": [
        "### Setup TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwHs1VJ1JpeT",
        "colab_type": "code",
        "outputId": "b57964cd-926d-4208-b7de-4fe3507a3a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "# create tpu resolver and strategy\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e2ce34b739ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grpc://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_connect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtpu_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'COLAB_TPU_ADDR'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mttn0WDMzPYe",
        "colab_type": "text"
      },
      "source": [
        "### Load Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkyJHIRuY7l9",
        "colab_type": "code",
        "outputId": "f3206d66-7300-4208-a9e5-ab0a6ddb57cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jMH1MIz7l1p",
        "colab_type": "text"
      },
      "source": [
        "Define Task Flag Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWeeDaZv7oMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SHORT_ANS_YESNO = 'short_ans_yesno'\n",
        "SHORT_ANS_ENTITY = 'short_ans_entity'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_VESswyzURY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_short_ans_train_dataset(task=SHORT_ANS_YESNO):\n",
        "  assert task in {SHORT_ANS_YESNO, SHORT_ANS_ENTITY}, \\\n",
        "    f\"task should be {SHORT_ANS_YESNO} or {SHORT_ANS_ENTITY}\"\n",
        "\n",
        "  SHORT_ANS_YESNO_DF = f\"{SHORT_ANS_YESNO}.pkl\"\n",
        "  SHORT_ANS_ENTITY_DF = f\"{SHORT_ANS_ENTITY}.pkl\"\n",
        "  if task == SHORT_ANS_YESNO:\n",
        "    datapath = f\"drive/My Drive/{SHORT_ANS_YESNO_DF}\"\n",
        "    if not os.path.exists(datapath):\n",
        "      print(\"short answer yesno dataset is not found!\")\n",
        "      return\n",
        "  elif task == SHORT_ANS_ENTITY:\n",
        "    datapath = f\"drive/My Drive/{SHORT_ANS_ENTITY_DF}\"\n",
        "    if not os.path.exists(f\"drive/My Drive/{SHORT_ANS_ENTITY_DF}\"):\n",
        "      print(\"short answer entity dataset is not found!\")\n",
        "      return\n",
        "  \n",
        "  return pd.read_pickle(datapath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "122uZLSRwAyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = read_short_ans_train_dataset(task=SHORT_ANS_ENTITY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxEk3D3Fzlda",
        "colab_type": "text"
      },
      "source": [
        "If training dataset is not found, please check this [Colab notebook for preparing training data](https://colab.research.google.com/drive/122bYIInseyFwrRFlTNEGLSNFP594i9OV)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGH3VWU-0cqu",
        "colab_type": "code",
        "outputId": "5d5a1b31-859e-47d1-e665-6a879f952997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "print(len(train_df))\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_id</th>\n",
              "      <th>segment_id</th>\n",
              "      <th>mask_id</th>\n",
              "      <th>label_start_token</th>\n",
              "      <th>label_end_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[2, 56, 25, 14, 127, 757, 275, 16, 17034, 8, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2, 184, 31, 9, 5909, 154, 449, 72, 25, 14, 44...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[2, 98, 1001, 16, 4270, 8005, 4330, 1384, 209,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2, 72, 41, 14, 127, 4041, 19, 14, 4101, 3, 13...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2, 72, 257, 169, 3409, 16931, 16, 14, 9358, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            token_id  ... label_end_token\n",
              "0  [2, 56, 25, 14, 127, 757, 275, 16, 17034, 8, 1...  ...              39\n",
              "1  [2, 184, 31, 9, 5909, 154, 449, 72, 25, 14, 44...  ...              18\n",
              "2  [2, 98, 1001, 16, 4270, 8005, 4330, 1384, 209,...  ...               0\n",
              "3  [2, 72, 41, 14, 127, 4041, 19, 14, 4101, 3, 13...  ...              18\n",
              "4  [2, 72, 257, 169, 3409, 16931, 16, 14, 9358, 1...  ...              20\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXR6_Htj0uzq",
        "colab_type": "text"
      },
      "source": [
        "Create distributed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HxCxGU_E3PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def short_ans_df_to_dataset(df, batch_size=16, task=SHORT_ANS_YESNO, dist_train=True):\n",
        "  assert task in {SHORT_ANS_YESNO, SHORT_ANS_ENTITY}, \\\n",
        "    f\"task should be {SHORT_ANS_YESNO} or {SHORT_ANS_ENTITY}\"\n",
        "\n",
        "  df = df.copy()\n",
        "\n",
        "  if task == 'short_ans_yesno':\n",
        "    label_yes_no = df.pop('label_yes_no')\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(df), label_yes_no))\n",
        "  elif task == 'short_ans_entity':\n",
        "    label_start_token = df.pop('label_start_token')\n",
        "    label_end_token = df.pop('label_end_token')\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(df), label_start_token, label_end_token))\n",
        "  \n",
        "  dataset = (dataset\n",
        "              .shuffle(buffer_size=len(df))\n",
        "              .batch(batch_size, drop_remainder=True)\n",
        "            )\n",
        "  \n",
        "  return (\n",
        "    tpu_strategy.experimental_distribute_dataset(dataset) \n",
        "    if dist_train else dataset\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHOlqYzHE3Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist_train_ds = short_ans_df_to_dataset(train_df, task=SHORT_ANS_ENTITY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjA31ont0-5Y",
        "colab_type": "text"
      },
      "source": [
        "### [Short Ans YESNO] Create TFAlbertForSequenceClassification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrGylNO5bJTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFAlbertForSequenceClassification(TFAlbertPreTrainedModel):\n",
        "  def __init__(self, config, *inputs, **kwargs):\n",
        "    super(TFAlbertForSequenceClassification, self).__init__(config, *inputs, **kwargs)\n",
        "    self.num_labels = config.num_labels\n",
        "\n",
        "    self.albert = TFAlbertModel(config, name=\"albert\")\n",
        "    self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = tf.keras.layers.Dense(\n",
        "      config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"classifier\"\n",
        "    )\n",
        "\n",
        "  def call(self, inputs, **kwargs):\n",
        "    outputs = self.albert(inputs, **kwargs)\n",
        "\n",
        "    pooled_output = outputs[1]\n",
        "\n",
        "    pooled_output = self.dropout(pooled_output, training=kwargs.get(\"training\", False))\n",
        "    logits = self.classifier(pooled_output)\n",
        "\n",
        "    outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "    return outputs  # logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLfwX3oay58d",
        "colab_type": "text"
      },
      "source": [
        "### [Short Ans Entity]Create TFAlbertForQuestionAnswering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n5yU-Edz0-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFAlbertForQuestionAnswering(TFAlbertPreTrainedModel):\n",
        "  def __init__(self, config, *inputs, **kwargs):\n",
        "    super().__init__(config, *inputs, **kwargs)\n",
        "    self.num_labels = config.num_labels\n",
        "\n",
        "    self.albert = TFAlbertModel(config, name=\"albert\")\n",
        "    self.qa_outputs = tf.keras.layers.Dense(\n",
        "      config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"qa_outputs\"\n",
        "    )\n",
        "\n",
        "  def call(self, inputs, **kwargs):  \n",
        "    outputs = self.albert(inputs, **kwargs)\n",
        "\n",
        "    sequence_output = outputs[0]\n",
        "\n",
        "    logits = self.qa_outputs(sequence_output)\n",
        "    start_logits, end_logits = tf.split(logits, 2, axis=-1)\n",
        "    start_logits = tf.squeeze(start_logits, axis=-1)\n",
        "    end_logits = tf.squeeze(end_logits, axis=-1)\n",
        "\n",
        "    outputs = (start_logits, end_logits,) + outputs[2:]\n",
        "\n",
        "    return outputs  # start_logits, end_logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XUdsREA06dk",
        "colab_type": "text"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q46cF6oRfCVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_short_ans_model(task=SHORT_ANS_YESNO):\n",
        "  assert task in {SHORT_ANS_YESNO, SHORT_ANS_ENTITY}, \\\n",
        "    f\"task should be {SHORT_ANS_YESNO} or {SHORT_ANS_ENTITY}\"\n",
        "\n",
        "  # input layers\n",
        "  token_ids = keras.Input(shape=(512,), dtype='int32', name='token_ids')\n",
        "  segment_ids = keras.Input(shape=(512,), dtype='int32', name='segment_ids')\n",
        "  mask_ids = keras.Input(shape=(512,), dtype='int32', name='mask_ids')\n",
        "\n",
        "  if task == SHORT_ANS_YESNO:\n",
        "    config = AlbertConfig.from_pretrained('albert-base-v2', num_labels=3)\n",
        "    albert_qa_layer = TFAlbertForSequenceClassification(config)\n",
        "  else:\n",
        "    albert_qa_layer = TFAlbertForQuestionAnswering.from_pretrained('albert-base-v2')\n",
        "\n",
        "  # both tasks use the same input format\n",
        "  albert_qa_outputs = albert_qa_layer([token_ids, mask_ids, segment_ids])\n",
        "\n",
        "  if task == SHORT_ANS_YESNO:\n",
        "    logits = albert_qa_outputs[0]\n",
        "\n",
        "    # create model\n",
        "    model = keras.Model(\n",
        "      inputs=[token_ids, mask_ids, segment_ids], \n",
        "      outputs=[logits]\n",
        "    )\n",
        "  else:\n",
        "    start_logits, end_logits = albert_qa_outputs[:2]\n",
        "\n",
        "    # create model\n",
        "    model = keras.Model(\n",
        "      inputs=[token_ids, mask_ids, segment_ids], \n",
        "      outputs=[start_logits, end_logits]\n",
        "    )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQwjT3-S1Quq",
        "colab_type": "text"
      },
      "source": [
        "### TPU Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N9ZdkZI5hZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_short_ans_using_tpu(\n",
        "    dist_train_ds, \n",
        "    task=SHORT_ANS_YESNO, \n",
        "    learning_rate=2e-5, \n",
        "    epsilon=1e-8, \n",
        "    epochs=10,\n",
        "    batch_size=16\n",
        "):\n",
        "  @tf.function\n",
        "  def train_step(dist_inputs, task=SHORT_ANS_YESNO):\n",
        "    # calculate loss and gradient for each replica\n",
        "    def step_fn_yesno(inputs):\n",
        "      features, label_yes_no = inputs\n",
        "      one_hot_label = tf.one_hot(label_yes_no, 3)\n",
        "      one_hot_label_index = tf.argmax(one_hot_label, axis=1)\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "        logits = model(features)\n",
        "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=one_hot_label_index, logits=logits)\n",
        "        avg_loss = loss / batch_size\n",
        "\n",
        "      gradients = tape.gradient(avg_loss, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "      train_loss(avg_loss)\n",
        "      label_yes_no_train_accuracy(one_hot_label_index, logits)\n",
        "\n",
        "      return avg_loss\n",
        "\n",
        "    def step_fn_entity(inputs):\n",
        "      features, start_tokens, end_tokens = inputs\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "        start_logits, end_logits = model(features)\n",
        "          \n",
        "        start_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=start_tokens, logits=start_logits)\n",
        "        end_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=end_tokens, logits=end_logits)\n",
        "\n",
        "        loss = (start_loss + end_loss) / 2.0\n",
        "        avg_loss = loss / batch_size\n",
        "\n",
        "      gradients = tape.gradient(avg_loss, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "      train_loss(avg_loss)\n",
        "      start_train_accuracy(start_tokens, start_logits)\n",
        "      end_train_accuracy(end_tokens, end_logits)\n",
        "\n",
        "      return avg_loss\n",
        "    \n",
        "    # combine loss for all replicas\n",
        "    if task == SHORT_ANS_YESNO:\n",
        "      per_example_losses = tpu_strategy.experimental_run_v2(step_fn_yesno, args=(dist_inputs,))\n",
        "    else:\n",
        "      per_example_losses = tpu_strategy.experimental_run_v2(step_fn_entity, args=(dist_inputs,))\n",
        "    sum_loss = tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, per_example_losses, axis=0)\n",
        "    return sum_loss  \n",
        "  \n",
        "  assert task in {SHORT_ANS_YESNO, SHORT_ANS_ENTITY}, \\\n",
        "    f\"task should be {SHORT_ANS_YESNO} or {SHORT_ANS_ENTITY}\"\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  if task == SHORT_ANS_YESNO:\n",
        "    label_yes_no_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='label_yes_no_train_accuracy'\n",
        "    )\n",
        "  else:\n",
        "    start_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='start_train_accuracy'\n",
        "    )\n",
        "    end_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='end_train_accuracy'\n",
        "    )\n",
        "\n",
        "  with tpu_strategy.scope():\n",
        "    model = create_short_ans_model(task)\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "      learning_rate=learning_rate, \n",
        "      epsilon=epsilon\n",
        "    )\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    if task == SHORT_ANS_YESNO:\n",
        "      label_yes_no_train_accuracy.reset_states()\n",
        "    else:\n",
        "      start_train_accuracy.reset_states()\n",
        "      end_train_accuracy.reset_states()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      i = 0\n",
        "      for inputs in dist_train_ds:\n",
        "        train_step(inputs, task)\n",
        "        i = i + 1\n",
        "        \n",
        "        training_result = f\"epoch: {epoch}, batch: {i}, loss: {train_loss.result()}, \"\n",
        "        if task == SHORT_ANS_YESNO:\n",
        "          training_result += f\"label_yes_no_train_accuracy: {label_yes_no_train_accuracy.result()*100}\"\n",
        "        else:\n",
        "          training_result += f\"start_accuracy: {start_train_accuracy.result()*100}, end_accuracy: {end_train_accuracy.result()*100}\"\n",
        "        print(training_result)\n",
        "\n",
        "        train_loss.reset_states()\n",
        "        if task == SHORT_ANS_YESNO:\n",
        "          label_yes_no_train_accuracy.reset_states()\n",
        "        else:\n",
        "          start_train_accuracy.reset_states()\n",
        "          end_train_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSJmGOkZ-jy-",
        "colab_type": "code",
        "outputId": "b347e44b-7f1d-4df0-b3b8-547a9a4b6563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_short_ans_using_tpu(dist_train_ds, task=SHORT_ANS_ENTITY)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function train_short_ans_using_tpu.<locals>.train_step at 0x7f92ae8e0b70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Cell is empty\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function train_short_ans_using_tpu.<locals>.train_step at 0x7f92ae8e0b70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Cell is empty\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function train_short_ans_using_tpu.<locals>.train_step at 0x7f92ae8e0b70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Cell is empty\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_for_question_answering_1/albert/pooler/kernel:0', 'tf_albert_for_question_answering_1/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_for_question_answering_1/albert/pooler/kernel:0', 'tf_albert_for_question_answering_1/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_for_question_answering_1/albert/pooler/kernel:0', 'tf_albert_for_question_answering_1/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_for_question_answering_1/albert/pooler/kernel:0', 'tf_albert_for_question_answering_1/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, batch: 1, loss: 0.38915392756462097, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 2, loss: 0.3564722537994385, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 3, loss: 0.36094802618026733, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 4, loss: 0.35990041494369507, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 5, loss: 0.24091550707817078, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 6, loss: 0.2908211648464203, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 7, loss: 0.3150749206542969, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 8, loss: 0.2462438941001892, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 9, loss: 0.2815420627593994, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 10, loss: 0.1546507030725479, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 11, loss: 0.181248277425766, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 12, loss: 0.2030486911535263, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 13, loss: 0.18973150849342346, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 14, loss: 0.20355919003486633, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 15, loss: 0.2789771258831024, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 16, loss: 0.29145359992980957, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 17, loss: 0.1915285736322403, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 18, loss: 0.29845404624938965, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 19, loss: 0.285616397857666, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 20, loss: 0.1880531907081604, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 21, loss: 0.20771506428718567, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 22, loss: 0.2997812330722809, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 23, loss: 0.2548205852508545, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 24, loss: 0.267267107963562, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 25, loss: 0.3225720524787903, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 26, loss: 0.2481738179922104, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 27, loss: 0.27775633335113525, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 28, loss: 0.20373950898647308, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 29, loss: 0.32042932510375977, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 30, loss: 0.1101064458489418, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 31, loss: 0.17949381470680237, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 32, loss: 0.07606131583452225, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 33, loss: 0.19060391187667847, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 34, loss: 0.3328295350074768, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 35, loss: 0.1687195748090744, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 36, loss: 0.21392971277236938, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 37, loss: 0.3336131274700165, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 38, loss: 0.24197930097579956, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 39, loss: 0.10689796507358551, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 40, loss: 0.28658705949783325, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 41, loss: 0.2753439247608185, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 42, loss: 0.15760907530784607, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 43, loss: 0.3598785996437073, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 44, loss: 0.1792718768119812, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 45, loss: 0.3508567810058594, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 46, loss: 0.1997613161802292, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 47, loss: 0.30471569299697876, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 48, loss: 0.064083993434906, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 49, loss: 0.16002285480499268, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 50, loss: 0.2058018296957016, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 51, loss: 0.35428163409233093, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 52, loss: 0.2472752034664154, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 53, loss: 0.23737691342830658, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 54, loss: 0.34560298919677734, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 55, loss: 0.26786577701568604, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 56, loss: 0.10130936652421951, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 57, loss: 0.25286179780960083, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 58, loss: 0.020542381331324577, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 59, loss: 0.14145779609680176, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 60, loss: 0.3154240846633911, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 61, loss: 0.27576130628585815, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 62, loss: 0.2561284005641937, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 63, loss: 0.16830097138881683, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 64, loss: 0.3219870328903198, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 65, loss: 0.20079244673252106, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 66, loss: 0.19194263219833374, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 67, loss: 0.3098800480365753, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 68, loss: 0.15785574913024902, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 69, loss: 0.1468893587589264, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 70, loss: 0.17469029128551483, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 71, loss: 0.18518997728824615, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 72, loss: 0.13522650301456451, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 73, loss: 0.22718816995620728, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 74, loss: 0.21633177995681763, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 75, loss: 0.2765660881996155, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 76, loss: 0.1779734492301941, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 77, loss: 0.25246796011924744, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 78, loss: 0.10662494599819183, start_accuracy: 100.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 79, loss: 0.15797364711761475, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 80, loss: 0.23306743800640106, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 81, loss: 0.35816794633865356, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 82, loss: 0.21810507774353027, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 83, loss: 0.24731740355491638, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 84, loss: 0.15733873844146729, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 85, loss: 0.16337734460830688, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 86, loss: 0.14577388763427734, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 87, loss: 0.37203532457351685, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 88, loss: 0.20285169780254364, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 89, loss: 0.17169524729251862, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 90, loss: 0.2579326033592224, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 91, loss: 0.24826741218566895, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 92, loss: 0.17528365552425385, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 93, loss: 0.20209015905857086, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 94, loss: 0.17334766685962677, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 95, loss: 0.19440853595733643, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 96, loss: 0.22426925599575043, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 97, loss: 0.18826019763946533, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 98, loss: 0.25318658351898193, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 99, loss: 0.37816065549850464, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 100, loss: 0.15596511960029602, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 101, loss: 0.16486379504203796, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 102, loss: 0.27778100967407227, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 103, loss: 0.1764284074306488, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 104, loss: 0.19773435592651367, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 105, loss: 0.2580796182155609, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 106, loss: 0.1877131313085556, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 107, loss: 0.24657846987247467, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 108, loss: 0.29581713676452637, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 109, loss: 0.3484160900115967, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 110, loss: 0.28331249952316284, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 111, loss: 0.249658465385437, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 112, loss: 0.21020419895648956, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 113, loss: 0.28289592266082764, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 114, loss: 0.14721514284610748, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 115, loss: 0.14713077247142792, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 116, loss: 0.163790762424469, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 117, loss: 0.1443682760000229, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 118, loss: 0.09133750945329666, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 119, loss: 0.1522163301706314, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 120, loss: 0.09416674822568893, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 121, loss: 0.30997705459594727, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 122, loss: 0.2457282841205597, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 123, loss: 0.08287767320871353, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 124, loss: 0.15892361104488373, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 125, loss: 0.1034354642033577, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 126, loss: 0.1335005909204483, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 127, loss: 0.3204706609249115, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 128, loss: 0.32357853651046753, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 129, loss: 0.33014625310897827, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 130, loss: 0.22163422405719757, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 131, loss: 0.11368316411972046, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 132, loss: 0.17449282109737396, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 133, loss: 0.27527570724487305, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 134, loss: 0.15562063455581665, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 135, loss: 0.16669954359531403, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 136, loss: 0.17380453646183014, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 137, loss: 0.3674771189689636, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 138, loss: 0.2247685194015503, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 139, loss: 0.361360639333725, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 140, loss: 0.03859664127230644, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 141, loss: 0.06116270273923874, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 142, loss: 0.31149786710739136, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 143, loss: 0.03607069328427315, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 144, loss: 0.3088407516479492, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 145, loss: 0.12185889482498169, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 146, loss: 0.19911187887191772, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 147, loss: 0.202274352312088, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 148, loss: 0.3845917582511902, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 149, loss: 0.2760225236415863, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 150, loss: 0.3525654077529907, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 151, loss: 0.3178068995475769, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 152, loss: 0.30503973364830017, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 153, loss: 0.183794304728508, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 154, loss: 0.16854867339134216, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 155, loss: 0.16654333472251892, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 156, loss: 0.3032439947128296, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 157, loss: 0.2257339358329773, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 158, loss: 0.29336434602737427, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 159, loss: 0.05362795293331146, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 160, loss: 0.15561431646347046, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 161, loss: 0.13878463208675385, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 162, loss: 0.1227712631225586, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 163, loss: 0.27163276076316833, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 164, loss: 0.05939152091741562, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 165, loss: 0.05190414935350418, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 166, loss: 0.147744283080101, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 167, loss: 0.2092619687318802, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 168, loss: 0.2954045832157135, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 169, loss: 0.3104444444179535, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 170, loss: 0.24802225828170776, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 171, loss: 0.07274310290813446, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 172, loss: 0.20219092071056366, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 173, loss: 0.2448512613773346, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 174, loss: 0.1842832863330841, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 175, loss: 0.03215610980987549, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 176, loss: 0.18111348152160645, start_accuracy: 50.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 177, loss: 0.3247168958187103, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 178, loss: 0.3809066414833069, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 179, loss: 0.25365927815437317, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 180, loss: 0.32928231358528137, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 181, loss: 0.22539012134075165, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 182, loss: 0.21150125563144684, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 183, loss: 0.13354133069515228, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 184, loss: 0.24343857169151306, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 185, loss: 0.07639139145612717, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 186, loss: 0.08887343108654022, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 187, loss: 0.10931669920682907, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 188, loss: 0.1141965389251709, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 189, loss: 0.07018870115280151, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 190, loss: 0.30129241943359375, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 191, loss: 0.04605909436941147, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 192, loss: 0.16866780817508698, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 193, loss: 0.3321768045425415, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 194, loss: 0.1651131957769394, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 195, loss: 0.3347844183444977, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 196, loss: 0.23088130354881287, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 197, loss: 0.25689390301704407, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 198, loss: 0.25110113620758057, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 199, loss: 0.1705675721168518, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 200, loss: 0.1775692254304886, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 201, loss: 0.17704680562019348, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 202, loss: 0.15213093161582947, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 203, loss: 0.33014535903930664, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 204, loss: 0.12732329964637756, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 205, loss: 0.2112562358379364, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 206, loss: 0.23127023875713348, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 207, loss: 0.27942466735839844, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 208, loss: 0.17135962843894958, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 209, loss: 0.11904020607471466, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 210, loss: 0.2988337576389313, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 211, loss: 0.3536415994167328, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 212, loss: 0.024182815104722977, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 213, loss: 0.09058253467082977, start_accuracy: 50.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 214, loss: 0.2963642179965973, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 215, loss: 0.11678902804851532, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 216, loss: 0.20178690552711487, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 217, loss: 0.264122873544693, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 218, loss: 0.2189815789461136, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 219, loss: 0.1843561828136444, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 220, loss: 0.28611019253730774, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 221, loss: 0.32226699590682983, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 222, loss: 0.2192680686712265, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 223, loss: 0.2767229676246643, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 224, loss: 0.29104453325271606, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 225, loss: 0.14308826625347137, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 226, loss: 0.05748392641544342, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 227, loss: 0.26367419958114624, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 228, loss: 0.11895467340946198, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 229, loss: 0.255729079246521, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 230, loss: 0.20298981666564941, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 231, loss: 0.17742270231246948, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 232, loss: 0.2908724546432495, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 233, loss: 0.3197034001350403, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 234, loss: 0.1779305338859558, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 235, loss: 0.296903133392334, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 236, loss: 0.24364230036735535, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 237, loss: 0.20625615119934082, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 238, loss: 0.17703406512737274, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 239, loss: 0.20870178937911987, start_accuracy: 50.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 240, loss: 0.2709221839904785, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 241, loss: 0.16585737466812134, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 242, loss: 0.0696956217288971, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 243, loss: 0.17565321922302246, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 244, loss: 0.2098107933998108, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 245, loss: 0.16522735357284546, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 246, loss: 0.30937933921813965, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 247, loss: 0.2982962727546692, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 248, loss: 0.21547259390354156, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 249, loss: 0.3942634165287018, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 250, loss: 0.05515890195965767, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 251, loss: 0.32591795921325684, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 252, loss: 0.22756054997444153, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 253, loss: 0.13602131605148315, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 254, loss: 0.18864457309246063, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 255, loss: 0.19021457433700562, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 256, loss: 0.08409284800291061, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 257, loss: 0.24185699224472046, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 258, loss: 0.3212297558784485, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 259, loss: 0.1365857720375061, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 260, loss: 0.16609744727611542, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 261, loss: 0.0557318814098835, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 262, loss: 0.05344267562031746, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 263, loss: 0.4796485900878906, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 264, loss: 0.07506512850522995, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 265, loss: 0.1739291548728943, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 266, loss: 0.17321327328681946, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 267, loss: 0.2566620111465454, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 268, loss: 0.24013498425483704, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 269, loss: 0.18916913866996765, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 270, loss: 0.10903352499008179, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 271, loss: 0.16980654001235962, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 272, loss: 0.1611011028289795, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 273, loss: 0.18105894327163696, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 274, loss: 0.04744908958673477, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 275, loss: 0.21389760076999664, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 276, loss: 0.1464664340019226, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 277, loss: 0.318291038274765, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 278, loss: 0.346604585647583, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 279, loss: 0.34979790449142456, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 280, loss: 0.11832452565431595, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 281, loss: 0.1358015090227127, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 282, loss: 0.27143535017967224, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 283, loss: 0.1949649155139923, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 284, loss: 0.15968644618988037, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 285, loss: 0.16124796867370605, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 286, loss: 0.2032126784324646, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 287, loss: 0.19216860830783844, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 288, loss: 0.23549315333366394, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 289, loss: 0.07245077192783356, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 290, loss: 0.17225641012191772, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 291, loss: 0.16430655121803284, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 292, loss: 0.14708630740642548, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 293, loss: 0.1677299439907074, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 294, loss: 0.15679579973220825, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 295, loss: 0.3703097105026245, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 296, loss: 0.21912643313407898, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 297, loss: 0.3953508138656616, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 298, loss: 0.04398501664400101, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 299, loss: 0.2242702692747116, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 300, loss: 0.04549088329076767, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 301, loss: 0.22366580367088318, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 302, loss: 0.056169331073760986, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 303, loss: 0.10804641246795654, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 304, loss: 0.19680920243263245, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 305, loss: 0.21281468868255615, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 306, loss: 0.03973342105746269, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 307, loss: 0.28222545981407166, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 308, loss: 0.16423864662647247, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 309, loss: 0.13718242943286896, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 310, loss: 0.13984502851963043, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 311, loss: 0.23189997673034668, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 312, loss: 0.2496975213289261, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 313, loss: 0.21089406311511993, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 314, loss: 0.17191827297210693, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 315, loss: 0.16226154565811157, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 316, loss: 0.17183184623718262, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 317, loss: 0.21812832355499268, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 318, loss: 0.0247330442070961, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 319, loss: 0.27556902170181274, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 320, loss: 0.296833872795105, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 321, loss: 0.11802326887845993, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 322, loss: 0.23081043362617493, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 323, loss: 0.27439385652542114, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 324, loss: 0.27445095777511597, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 325, loss: 0.1629878431558609, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 326, loss: 0.2760709226131439, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 327, loss: 0.11091835796833038, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 328, loss: 0.11524602770805359, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 329, loss: 0.23538845777511597, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 330, loss: 0.23149311542510986, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 331, loss: 0.2604468762874603, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 332, loss: 0.17099323868751526, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 333, loss: 0.1506892591714859, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 334, loss: 0.06813006103038788, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 335, loss: 0.26141974329948425, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 336, loss: 0.05442856252193451, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 337, loss: 0.049126334488391876, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 338, loss: 0.25453928112983704, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 339, loss: 0.274445116519928, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 340, loss: 0.1792851984500885, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 341, loss: 0.15234781801700592, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 342, loss: 0.2567126750946045, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 343, loss: 0.15571530163288116, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 344, loss: 0.1068917065858841, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 345, loss: 0.3009515404701233, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 346, loss: 0.2080734670162201, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 347, loss: 0.17089250683784485, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 348, loss: 0.26419755816459656, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 349, loss: 0.21274983882904053, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 350, loss: 0.25821781158447266, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 351, loss: 0.214262917637825, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 352, loss: 0.24077890813350677, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 353, loss: 0.27841442823410034, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 354, loss: 0.19881625473499298, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 355, loss: 0.2744462788105011, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 356, loss: 0.2786681652069092, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 357, loss: 0.2883967161178589, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 358, loss: 0.17135518789291382, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 359, loss: 0.06518690288066864, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 360, loss: 0.2842335104942322, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 361, loss: 0.14832130074501038, start_accuracy: 50.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 362, loss: 0.05050741508603096, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 363, loss: 0.02676130086183548, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 364, loss: 0.021899079903960228, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 365, loss: 0.10964994132518768, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 366, loss: 0.3063203692436218, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 367, loss: 0.2939744293689728, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 368, loss: 0.16921421885490417, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 369, loss: 0.2561517357826233, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 370, loss: 0.12942826747894287, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 371, loss: 0.34487003087997437, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 372, loss: 0.1620863974094391, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 373, loss: 0.1820562779903412, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 374, loss: 0.16476361453533173, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 375, loss: 0.29957401752471924, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 376, loss: 0.17586851119995117, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 377, loss: 0.21830156445503235, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 378, loss: 0.1480071246623993, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 379, loss: 0.30083972215652466, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 380, loss: 0.16838037967681885, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 381, loss: 0.19739273190498352, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 382, loss: 0.187597393989563, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 383, loss: 0.18433406949043274, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 384, loss: 0.17828448116779327, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 385, loss: 0.22821259498596191, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 386, loss: 0.2592613697052002, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 387, loss: 0.20658567547798157, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 388, loss: 0.2082492709159851, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 389, loss: 0.25455132126808167, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 390, loss: 0.16278354823589325, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 391, loss: 0.28859588503837585, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 392, loss: 0.21496419608592987, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 393, loss: 0.34605658054351807, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 394, loss: 0.13706621527671814, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 395, loss: 0.3836778998374939, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 396, loss: 0.20539718866348267, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 397, loss: 0.24350889027118683, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 398, loss: 0.055002935230731964, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 399, loss: 0.14285396039485931, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 400, loss: 0.19107283651828766, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 401, loss: 0.16993270814418793, start_accuracy: 0.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 402, loss: 0.22201429307460785, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 403, loss: 0.190349742770195, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 404, loss: 0.05512246489524841, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 405, loss: 0.23055106401443481, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 406, loss: 0.1600876748561859, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 407, loss: 0.10685084760189056, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 408, loss: 0.09934459626674652, start_accuracy: 100.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 409, loss: 0.17048218846321106, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 410, loss: 0.28518855571746826, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 411, loss: 0.18072296679019928, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 412, loss: 0.09428583830595016, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 413, loss: 0.26316511631011963, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 414, loss: 0.1962326169013977, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 415, loss: 0.07194571197032928, start_accuracy: 50.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 416, loss: 0.16968083381652832, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 417, loss: 0.2884420156478882, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 418, loss: 0.2854326665401459, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 419, loss: 0.13333626091480255, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 420, loss: 0.25655892491340637, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 421, loss: 0.06229769438505173, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 422, loss: 0.2889711260795593, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 423, loss: 0.015940219163894653, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 424, loss: 0.2527107000350952, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 425, loss: 0.2301204353570938, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 426, loss: 0.28073960542678833, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 427, loss: 0.29274627566337585, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 428, loss: 0.2944346070289612, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 429, loss: 0.20825940370559692, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 430, loss: 0.09485852718353271, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 431, loss: 0.08393841981887817, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 432, loss: 0.14477111399173737, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 433, loss: 0.37486398220062256, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 434, loss: 0.13030266761779785, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 435, loss: 0.24956437945365906, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 436, loss: 0.2757378816604614, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 437, loss: 0.18680116534233093, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 438, loss: 0.1255100667476654, start_accuracy: 100.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 439, loss: 0.25331059098243713, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 440, loss: 0.1926712989807129, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 441, loss: 0.14894607663154602, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 442, loss: 0.2864302098751068, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 443, loss: 0.2055959701538086, start_accuracy: 0.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 444, loss: 0.2692311704158783, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 445, loss: 0.1484316736459732, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 446, loss: 0.1517808586359024, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 447, loss: 0.18015730381011963, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 448, loss: 0.3689118027687073, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 449, loss: 0.24176964163780212, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 450, loss: 0.21695373952388763, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 451, loss: 0.29152169823646545, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 452, loss: 0.041899409145116806, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 453, loss: 0.1347472220659256, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 454, loss: 0.0546424463391304, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 455, loss: 0.05178503692150116, start_accuracy: 50.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 456, loss: 0.16498807072639465, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 457, loss: 0.225179985165596, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 458, loss: 0.056912463158369064, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 459, loss: 0.19046838581562042, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 460, loss: 0.1815122812986374, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 461, loss: 0.14805708825588226, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 462, loss: 0.0280134417116642, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 463, loss: 0.12646540999412537, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 464, loss: 0.17611025273799896, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 465, loss: 0.33573052287101746, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 466, loss: 0.20379483699798584, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 467, loss: 0.14622598886489868, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 468, loss: 0.16692176461219788, start_accuracy: 50.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 469, loss: 0.07764542102813721, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 470, loss: 0.25676077604293823, start_accuracy: 50.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 471, loss: 0.18836820125579834, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 472, loss: 0.10279648751020432, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 473, loss: 0.2847442626953125, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 474, loss: 0.26152002811431885, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 475, loss: 0.17662572860717773, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 476, loss: 0.03335489332675934, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 477, loss: 0.2936915159225464, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 478, loss: 0.15754657983779907, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 479, loss: 0.14302076399326324, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 480, loss: 0.0438535250723362, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 481, loss: 0.04951896518468857, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 482, loss: 0.360016405582428, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 483, loss: 0.11060649156570435, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 484, loss: 0.1796826720237732, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 485, loss: 0.258110910654068, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 486, loss: 0.1502779722213745, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 487, loss: 0.28719812631607056, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 488, loss: 0.06814727187156677, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 489, loss: 0.2297467738389969, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 490, loss: 0.2131241261959076, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 491, loss: 0.21725678443908691, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 492, loss: 0.10075686872005463, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 493, loss: 0.337238073348999, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 494, loss: 0.3158949017524719, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 495, loss: 0.20245641469955444, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 496, loss: 0.18952420353889465, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 497, loss: 0.21833163499832153, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 498, loss: 0.21892134845256805, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 499, loss: 0.21733082830905914, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 500, loss: 0.3411497473716736, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 501, loss: 0.19966915249824524, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 502, loss: 0.1498674601316452, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 503, loss: 0.04905393719673157, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 504, loss: 0.03014327585697174, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 505, loss: 0.34974461793899536, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 506, loss: 0.044609736651182175, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 507, loss: 0.21917879581451416, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 508, loss: 0.2501707971096039, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 509, loss: 0.1365744024515152, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 510, loss: 0.32509687542915344, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 511, loss: 0.18283392488956451, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 512, loss: 0.2918962836265564, start_accuracy: 0.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 513, loss: 0.1699448972940445, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 514, loss: 0.269794762134552, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 515, loss: 0.2163146734237671, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 516, loss: 0.18696990609169006, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 517, loss: 0.1660965383052826, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 518, loss: 0.19995912909507751, start_accuracy: 0.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 519, loss: 0.22963038086891174, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 520, loss: 0.3294098377227783, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 521, loss: 0.13561436533927917, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 522, loss: 0.10939428210258484, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 523, loss: 0.31251105666160583, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 524, loss: 0.025585778057575226, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 525, loss: 0.16345123946666718, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 526, loss: 0.12057739496231079, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 527, loss: 0.13359896838665009, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 528, loss: 0.19961628317832947, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 529, loss: 0.11051122844219208, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 530, loss: 0.3022056818008423, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 531, loss: 0.2572906017303467, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 532, loss: 0.3305695056915283, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 533, loss: 0.20478995144367218, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 534, loss: 0.10405340045690536, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 535, loss: 0.35997986793518066, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 536, loss: 0.17138627171516418, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 537, loss: 0.25720399618148804, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 538, loss: 0.24867300689220428, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 539, loss: 0.210946723818779, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 540, loss: 0.19991368055343628, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 541, loss: 0.2494087666273117, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 542, loss: 0.27345505356788635, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 543, loss: 0.1888430267572403, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 544, loss: 0.21642285585403442, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 545, loss: 0.12198635190725327, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 546, loss: 0.22801977396011353, start_accuracy: 50.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 547, loss: 0.216866597533226, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 548, loss: 0.08600959181785583, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 549, loss: 0.3426722288131714, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 550, loss: 0.04917503520846367, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 551, loss: 0.07332894206047058, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 552, loss: 0.14880287647247314, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 553, loss: 0.024682534858584404, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 554, loss: 0.3484213948249817, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 555, loss: 0.30767834186553955, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 556, loss: 0.2906768321990967, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 557, loss: 0.17800430953502655, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 558, loss: 0.045264363288879395, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 559, loss: 0.12738478183746338, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 560, loss: 0.11871632933616638, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 561, loss: 0.0726432055234909, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 562, loss: 0.24731414020061493, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 563, loss: 0.295515239238739, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 564, loss: 0.32574915885925293, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 565, loss: 0.21888044476509094, start_accuracy: 0.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 566, loss: 0.20476005971431732, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 567, loss: 0.2441929280757904, start_accuracy: 50.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 568, loss: 0.1282309591770172, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 569, loss: 0.25004708766937256, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 570, loss: 0.10417047888040543, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 571, loss: 0.31074991822242737, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 572, loss: 0.0705481469631195, start_accuracy: 50.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 573, loss: 0.22842496633529663, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 574, loss: 0.30855512619018555, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 575, loss: 0.2681576609611511, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 576, loss: 0.24568308889865875, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 577, loss: 0.3204084634780884, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 578, loss: 0.14371874928474426, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 579, loss: 0.11825650930404663, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 580, loss: 0.1311054229736328, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 581, loss: 0.056597039103507996, start_accuracy: 50.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 582, loss: 0.3025699257850647, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 583, loss: 0.08063119649887085, start_accuracy: 50.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 584, loss: 0.2737503945827484, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 585, loss: 0.337795615196228, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 586, loss: 0.14467845857143402, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 587, loss: 0.3573493957519531, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 588, loss: 0.20026037096977234, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 589, loss: 0.13361115753650665, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 590, loss: 0.18252035975456238, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 591, loss: 0.22167253494262695, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 592, loss: 0.20006920397281647, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 593, loss: 0.20584245026111603, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 594, loss: 0.20837849378585815, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 595, loss: 0.018036525696516037, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 596, loss: 0.1559290587902069, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 597, loss: 0.15807059407234192, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 598, loss: 0.30212312936782837, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 599, loss: 0.2806670665740967, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 600, loss: 0.23100963234901428, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 601, loss: 0.23745745420455933, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 602, loss: 0.04930012673139572, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 603, loss: 0.15198630094528198, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 604, loss: 0.22650033235549927, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 605, loss: 0.3674624562263489, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 606, loss: 0.1871452033519745, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 607, loss: 0.2056780308485031, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 608, loss: 0.2817930281162262, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 609, loss: 0.2230694591999054, start_accuracy: 0.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 610, loss: 0.25790098309516907, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 611, loss: 0.2891073226928711, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 612, loss: 0.04847150295972824, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 613, loss: 0.04593304544687271, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 614, loss: 0.20926333963871002, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 615, loss: 0.3449755907058716, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 616, loss: 0.3246222734451294, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 617, loss: 0.03199915587902069, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 618, loss: 0.20992612838745117, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 619, loss: 0.24282771348953247, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 620, loss: 0.16385042667388916, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 621, loss: 0.21629557013511658, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 622, loss: 0.2491026222705841, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 623, loss: 0.28042328357696533, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 624, loss: 0.09426847845315933, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 625, loss: 0.15139546990394592, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 626, loss: 0.18915356695652008, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 627, loss: 0.21844075620174408, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 628, loss: 0.29017171263694763, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 629, loss: 0.20494766533374786, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 630, loss: 0.2981109619140625, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 631, loss: 0.2831510901451111, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 632, loss: 0.24013713002204895, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 633, loss: 0.19819246232509613, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 634, loss: 0.27224814891815186, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 635, loss: 0.19310104846954346, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 636, loss: 0.28773653507232666, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 637, loss: 0.21361801028251648, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 638, loss: 0.31464871764183044, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 639, loss: 0.18818047642707825, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 640, loss: 0.04017409682273865, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 641, loss: 0.08242061734199524, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 642, loss: 0.16560102999210358, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 643, loss: 0.07149408757686615, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 644, loss: 0.18670137226581573, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 645, loss: 0.2452058643102646, start_accuracy: 50.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 646, loss: 0.20738613605499268, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 647, loss: 0.15964621305465698, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 648, loss: 0.1511591374874115, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 649, loss: 0.35520803928375244, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 650, loss: 0.09206459671258926, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 651, loss: 0.21087633073329926, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 652, loss: 0.2712397277355194, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 653, loss: 0.21639180183410645, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 654, loss: 0.162793830037117, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 655, loss: 0.31676483154296875, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 656, loss: 0.13772675395011902, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 657, loss: 0.04926325008273125, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 658, loss: 0.0659695416688919, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 659, loss: 0.27418750524520874, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 660, loss: 0.07860177755355835, start_accuracy: 50.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 661, loss: 0.29237687587738037, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 662, loss: 0.346600741147995, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 663, loss: 0.21270757913589478, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 664, loss: 0.20497214794158936, start_accuracy: 0.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 665, loss: 0.02373102307319641, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 666, loss: 0.36077219247817993, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 667, loss: 0.1875435709953308, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 668, loss: 0.32702380418777466, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 669, loss: 0.21135105192661285, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 670, loss: 0.20820625126361847, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 671, loss: 0.1925014853477478, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 672, loss: 0.292018860578537, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 673, loss: 0.2062014639377594, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 674, loss: 0.17951443791389465, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 675, loss: 0.07918210327625275, start_accuracy: 100.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 676, loss: 0.07093280553817749, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 677, loss: 0.3361648917198181, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 678, loss: 0.2431063950061798, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 679, loss: 0.31494349241256714, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 680, loss: 0.1999189257621765, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 681, loss: 0.2715599536895752, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 682, loss: 0.0902838334441185, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 683, loss: 0.30238497257232666, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 684, loss: 0.07731779664754868, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 685, loss: 0.1648941934108734, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 686, loss: 0.29484909772872925, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 687, loss: 0.21227958798408508, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 688, loss: 0.3019493818283081, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 689, loss: 0.2983441948890686, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 690, loss: 0.28624171018600464, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 691, loss: 0.056801196187734604, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 692, loss: 0.19355346262454987, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 693, loss: 0.122743159532547, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 694, loss: 0.268006294965744, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 695, loss: 0.19880442321300507, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 696, loss: 0.1634419858455658, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 697, loss: 0.06046861410140991, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 698, loss: 0.03164193406701088, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 699, loss: 0.29103055596351624, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 700, loss: 0.3203592300415039, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 701, loss: 0.21320831775665283, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 702, loss: 0.12184400856494904, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 703, loss: 0.3500783145427704, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 704, loss: 0.18625859916210175, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 705, loss: 0.057046882808208466, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 706, loss: 0.06217251718044281, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 707, loss: 0.01815119944512844, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 708, loss: 0.3115924000740051, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 709, loss: 0.1005883738398552, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 710, loss: 0.27587440609931946, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 711, loss: 0.2607666850090027, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 712, loss: 0.24672740697860718, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 713, loss: 0.1476603001356125, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 714, loss: 0.11370253562927246, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 715, loss: 0.173503115773201, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 716, loss: 0.2169250249862671, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 717, loss: 0.17449912428855896, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 718, loss: 0.13604971766471863, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 719, loss: 0.04541712999343872, start_accuracy: 100.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 720, loss: 0.18051820993423462, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 721, loss: 0.16590197384357452, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 722, loss: 0.23624667525291443, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 723, loss: 0.28413134813308716, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 724, loss: 0.2213989496231079, start_accuracy: 50.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 725, loss: 0.19921590387821198, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 726, loss: 0.16863301396369934, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 727, loss: 0.23773662745952606, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 728, loss: 0.22597715258598328, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 729, loss: 0.20777809619903564, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 730, loss: 0.2827446758747101, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 731, loss: 0.061372943222522736, start_accuracy: 50.0, end_accuracy: 100.0\n",
            "epoch: 0, batch: 732, loss: 0.19022855162620544, start_accuracy: 0.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 733, loss: 0.2679866850376129, start_accuracy: 0.0, end_accuracy: 0.0\n",
            "epoch: 0, batch: 734, loss: 0.18145859241485596, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 735, loss: 0.15639647841453552, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 736, loss: 0.21548472344875336, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 737, loss: 0.19491517543792725, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 738, loss: 0.10893501341342926, start_accuracy: 50.0, end_accuracy: 50.0\n",
            "epoch: 0, batch: 739, loss: 0.30833423137664795, start_accuracy: 0.0, end_accuracy: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-5051afa5c594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_short_ans_using_tpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_train_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSHORT_ANS_ENTITY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-a2b3e8e92922>\u001b[0m in \u001b[0;36mtrain_short_ans_using_tpu\u001b[0;34m(dist_train_ds, task, learning_rate, epsilon, epochs, batch_size)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtraining_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"epoch: {epoch}, batch: {i}, loss: {train_loss.result()}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSHORT_ANS_YESNO\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m           \u001b[0mtraining_result\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"label_yes_no_train_accuracy: {label_yes_no_train_accuracy.result()*100}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f89RPSsU-sEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}