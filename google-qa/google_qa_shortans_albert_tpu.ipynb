{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google-qa-shortans-albert-tpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c8282ea745d48db891417749e7584e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a52589dc373846eb9d87b7aa5e3c806f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dbd496aa7e3e4753ae4dcd9ad5f22a5b",
              "IPY_MODEL_3225434038114e1683afe1b7432cbd39"
            ]
          }
        },
        "a52589dc373846eb9d87b7aa5e3c806f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbd496aa7e3e4753ae4dcd9ad5f22a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d7da15a0a1a94c079a8ad4a83c04157e",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 534,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 534,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e585a3b86f14539993e9af758d3fb04"
          }
        },
        "3225434038114e1683afe1b7432cbd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a303f92dc71d4793813c55c3675a4f36",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 534/534 [00:00&lt;00:00, 27.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da8b163e6d2d441ea9ae8bc2eb2940e8"
          }
        },
        "d7da15a0a1a94c079a8ad4a83c04157e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e585a3b86f14539993e9af758d3fb04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a303f92dc71d4793813c55c3675a4f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da8b163e6d2d441ea9ae8bc2eb2940e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyyeh/kaggle/blob/master/google-qa/google_qa_shortans_albert_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCz27jWFozEp",
        "colab_type": "text"
      },
      "source": [
        "# TPU Training for NQA Short Answers\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEYxZcKazCWS",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g66cQjyblfno",
        "colab_type": "code",
        "outputId": "3e81d843-ed08-4428-cbd2-a9618f4221a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# make sure colab use tf2.x\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsMEk4HoJpbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2NdA7Cqh_74",
        "colab_type": "code",
        "outputId": "596ec837-0b67-4b1f-8299-b8da97c247ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# install huggingface transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\r\u001b[K     |▊                               | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 71kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 17.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 21.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from transformers) (1.18.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from transformers) (2.22.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (1.25.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=15e085e5d0e6f6ebc310d293a90cddb2350f644a5d51c6215bf6ddfb4a85241a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QMLgqUq08DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import TFAlbertPreTrainedModel, TFAlbertModel, AlbertConfig\n",
        "from transformers.modeling_tf_utils import get_initializer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZWoy20PzNEL",
        "colab_type": "text"
      },
      "source": [
        "### Setup TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwHs1VJ1JpeT",
        "colab_type": "code",
        "outputId": "35d57010-4806-4405-a5ae-82cc66fbc5bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "# create tpu resolver and strategy\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.68.211.146:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.68.211.146:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mttn0WDMzPYe",
        "colab_type": "text"
      },
      "source": [
        "### Load Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkyJHIRuY7l9",
        "colab_type": "code",
        "outputId": "01d2784e-4662-4a9e-e390-a6820dd7f77d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jMH1MIz7l1p",
        "colab_type": "text"
      },
      "source": [
        "Define Task Flag Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWeeDaZv7oMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SHORT_ANS_YESNO = 'short_ans_yesno'\n",
        "SHORT_ANS_ENTITY = 'short_ans_entity'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oF3jMGCLQN61",
        "colab": {}
      },
      "source": [
        "def read_short_ans_train_dataset(task=SHORT_ANS_YESNO):\n",
        "  assert task in {SHORT_ANS_YESNO, SHORT_ANS_ENTITY}, \\\n",
        "    f\"task should be {SHORT_ANS_YESNO} or {SHORT_ANS_ENTITY}\"\n",
        "\n",
        "  SHORT_ANS_YESNO_DF = f\"{SHORT_ANS_YESNO}.pkl\"\n",
        "  SHORT_ANS_ENTITY_DF = f\"{SHORT_ANS_ENTITY}.pkl\"\n",
        "  if task == SHORT_ANS_YESNO:\n",
        "    datapath = f\"drive/My Drive/{SHORT_ANS_YESNO_DF}\"\n",
        "    if not os.path.exists(datapath):\n",
        "      print(\"short answer yesno dataset is not found!\")\n",
        "      return\n",
        "  elif task == SHORT_ANS_ENTITY:\n",
        "    datapath = f\"drive/My Drive/{SHORT_ANS_ENTITY_DF}\"\n",
        "    if not os.path.exists(f\"drive/My Drive/{SHORT_ANS_ENTITY_DF}\"):\n",
        "      print(\"short answer entity dataset is not found!\")\n",
        "      return\n",
        "  \n",
        "  return pd.read_pickle(datapath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "122uZLSRwAyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = read_short_ans_train_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxEk3D3Fzlda",
        "colab_type": "text"
      },
      "source": [
        "If training dataset is not found, please check this [Colab notebook for preparing training data](https://colab.research.google.com/drive/122bYIInseyFwrRFlTNEGLSNFP594i9OV)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGH3VWU-0cqu",
        "colab_type": "code",
        "outputId": "361e2fa6-a245-4fae-c43f-d907b4dfec63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train_df = train_df[:80]\n",
        "print(len(train_df))\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label_yes_no</th>\n",
              "      <th>token_ids</th>\n",
              "      <th>segment_ids</th>\n",
              "      <th>mask_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 56, 25, 14, 127, 757, 275, 16, 17034, 8, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 184, 31, 9, 5909, 154, 449, 72, 25, 14, 44...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 98, 1001, 16, 4270, 8005, 4330, 1384, 209,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 72, 41, 14, 127, 4041, 19, 14, 4101, 3, 13...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 72, 257, 169, 3409, 16931, 16, 14, 9358, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label_yes_no  ...                                           mask_ids\n",
              "0             2  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "1             2  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "2             2  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "3             2  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "4             2  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXR6_Htj0uzq",
        "colab_type": "text"
      },
      "source": [
        "Create distributed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HxCxGU_E3PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def short_ans_df_to_dataset(df, batch_size=16, task=SHORT_ANS_YESNO, dist_train=True):\n",
        "  assert task in {SHORT_ANS_YESNO, SHORT_ANS_ENTITY}, \\\n",
        "    f\"task should be {SHORT_ANS_YESNO} or {SHORT_ANS_ENTITY}\"\n",
        "\n",
        "  df = df.copy()\n",
        "\n",
        "  if task == 'short_ans_yesno':\n",
        "    label_yes_no = df.pop('label_yes_no')\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(df), label_yes_no))\n",
        "  elif task == 'short_ans_entity':\n",
        "    label_start_token = df.pop('label_start_token')\n",
        "    label_end_token = df.pop('label_end_token')\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(df), label_start_token, label_end_token))\n",
        "  \n",
        "  dataset = (dataset\n",
        "              .shuffle(buffer_size=len(df))\n",
        "              .batch(batch_size, drop_remainder=True)\n",
        "            )\n",
        "  \n",
        "  return (\n",
        "    tpu_strategy.experimental_distribute_dataset(dataset) \n",
        "    if dist_train else dataset\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHOlqYzHE3Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist_train_ds = short_ans_df_to_dataset(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjA31ont0-5Y",
        "colab_type": "text"
      },
      "source": [
        "### [Short Ans YESNO] Create TFAlbertForSequenceClassification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrGylNO5bJTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFAlbertForSequenceClassification(TFAlbertPreTrainedModel):\n",
        "  def __init__(self, config, *inputs, **kwargs):\n",
        "    super(TFAlbertForSequenceClassification, self).__init__(config, *inputs, **kwargs)\n",
        "    self.num_labels = config.num_labels\n",
        "\n",
        "    self.albert = TFAlbertModel(config, name=\"albert\")\n",
        "    self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = tf.keras.layers.Dense(\n",
        "      config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"classifier\"\n",
        "    )\n",
        "\n",
        "  def call(self, inputs, **kwargs):\n",
        "    outputs = self.albert(inputs, **kwargs)\n",
        "\n",
        "    pooled_output = outputs[1]\n",
        "\n",
        "    pooled_output = self.dropout(pooled_output, training=kwargs.get(\"training\", False))\n",
        "    logits = self.classifier(pooled_output)\n",
        "\n",
        "    outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "    return outputs  # logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLfwX3oay58d",
        "colab_type": "text"
      },
      "source": [
        "### [Short Ans Entity]Create TFAlbertForQuestionAnswering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n5yU-Edz0-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFAlbertForQuestionAnswering(TFAlbertPreTrainedModel):\n",
        "  def __init__(self, config, *inputs, **kwargs):\n",
        "    super().__init__(config, *inputs, **kwargs)\n",
        "    self.num_labels = config.num_labels\n",
        "\n",
        "    self.albert = TFAlbertModel(config, name=\"albert\")\n",
        "    self.qa_outputs = tf.keras.layers.Dense(\n",
        "      config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"qa_outputs\"\n",
        "    )\n",
        "\n",
        "  def call(self, inputs, **kwargs):  \n",
        "    outputs = self.albert(inputs, **kwargs)\n",
        "\n",
        "    sequence_output = outputs[0]\n",
        "\n",
        "    logits = self.qa_outputs(sequence_output)\n",
        "    start_logits, end_logits = tf.split(logits, 2, axis=-1)\n",
        "    start_logits = tf.squeeze(start_logits, axis=-1)\n",
        "    end_logits = tf.squeeze(end_logits, axis=-1)\n",
        "\n",
        "    outputs = (start_logits, end_logits,) + outputs[2:]\n",
        "\n",
        "    return outputs  # start_logits, end_logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XUdsREA06dk",
        "colab_type": "text"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q46cF6oRfCVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_short_ans_model(task=SHORT_ANS_YESNO):\n",
        "  assert task in {SHORT_ANS_YESNO, SHORT_ANS_ENTITY}, \\\n",
        "    f\"task should be {SHORT_ANS_YESNO} or {SHORT_ANS_ENTITY}\"\n",
        "\n",
        "  # input layers\n",
        "  token_ids = keras.Input(shape=(512,), dtype='int32', name='token_ids')\n",
        "  segment_ids = keras.Input(shape=(512,), dtype='int32', name='segment_ids')\n",
        "  mask_ids = keras.Input(shape=(512,), dtype='int32', name='mask_ids')\n",
        "\n",
        "  if task == SHORT_ANS_YESNO:\n",
        "    config = AlbertConfig.from_pretrained('albert-base-v2', num_labels=3)\n",
        "    albert_qa_layer = TFAlbertForSequenceClassification(config)\n",
        "  else:\n",
        "    albert_qa_layer = TFAlbertForQuestionAnswering.from_pretrained('albert-base-v2')\n",
        "\n",
        "  # both tasks use the same input format\n",
        "  albert_qa_outputs = albert_qa_layer([token_ids, mask_ids, segment_ids])\n",
        "\n",
        "  if task == SHORT_ANS_YESNO:\n",
        "    logits = albert_qa_outputs[0]\n",
        "\n",
        "    # create model\n",
        "    model = keras.Model(\n",
        "      inputs=[token_ids, mask_ids, segment_ids], \n",
        "      outputs=[logits]\n",
        "    )\n",
        "  else:\n",
        "    start_logits, end_logits = albert_qa_outputs[:2]\n",
        "\n",
        "    # create model\n",
        "    model = keras.Model(\n",
        "      inputs=[token_ids, mask_ids, segment_ids], \n",
        "      outputs=[start_logits, end_logits]\n",
        "    )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQwjT3-S1Quq",
        "colab_type": "text"
      },
      "source": [
        "### TPU Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N9ZdkZI5hZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_short_ans_using_tpu(\n",
        "    dist_train_ds, \n",
        "    task=SHORT_ANS_YESNO, \n",
        "    learning_rate=2e-5, \n",
        "    epsilon=1e-8, \n",
        "    epochs=10,\n",
        "    batch_size=16\n",
        "):\n",
        "  @tf.function\n",
        "  def train_step(dist_inputs, task=SHORT_ANS_YESNO):\n",
        "    # calculate loss and gradient for each replica\n",
        "    def step_fn_yesno(inputs):\n",
        "      features, label_yes_no = inputs\n",
        "      one_hot_label = tf.one_hot(label_yes_no, 3)\n",
        "      one_hot_label_index = tf.argmax(one_hot_label, axis=1)\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "        logits = model(features)\n",
        "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=one_hot_label_index, logits=logits)\n",
        "        avg_loss = loss / batch_size\n",
        "\n",
        "      gradients = tape.gradient(avg_loss, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "      train_loss(avg_loss)\n",
        "      label_yes_no_train_accuracy(one_hot_label_index, logits)\n",
        "\n",
        "      return avg_loss\n",
        "\n",
        "    def step_fn_entity(inputs):\n",
        "      features, start_tokens, end_tokens = inputs\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "        start_logits, end_logits = model(features)\n",
        "          \n",
        "        start_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=start_tokens, logits=start_logits)\n",
        "        end_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=end_tokens, logits=end_logits)\n",
        "\n",
        "        loss = (start_loss + end_loss) / 2.0\n",
        "        avg_loss = loss / batch_size\n",
        "\n",
        "      gradients = tape.gradient(avg_loss, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "      train_loss(avg_loss)\n",
        "      start_train_accuracy(start_tokens, start_logits)\n",
        "      end_train_accuracy(end_tokens, end_logits)\n",
        "\n",
        "      return avg_loss\n",
        "    \n",
        "    # combine loss for all replicas\n",
        "    if task == SHORT_ANS_YESNO:\n",
        "      per_example_losses = tpu_strategy.experimental_run_v2(step_fn_yesno, args=(dist_inputs,))\n",
        "    else:\n",
        "      per_example_losses = tpu_strategy.experimental_run_v2(step_fn_entity, args=(dist_inputs,))\n",
        "    sum_loss = tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, per_example_losses, axis=0)\n",
        "    return sum_loss  \n",
        "  \n",
        "  assert task in {SHORT_ANS_YESNO, SHORT_ANS_ENTITY}, \\\n",
        "    f\"task should be {SHORT_ANS_YESNO} or {SHORT_ANS_ENTITY}\"\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  if task == SHORT_ANS_YESNO:\n",
        "    label_yes_no_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='label_yes_no_train_accuracy'\n",
        "    )\n",
        "  else:\n",
        "    start_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='start_train_accuracy'\n",
        "    )\n",
        "    end_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='end_train_accuracy'\n",
        "    )\n",
        "\n",
        "  with tpu_strategy.scope():\n",
        "    model = create_short_ans_model(task)\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "      learning_rate=learning_rate, \n",
        "      epsilon=epsilon\n",
        "    )\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    if task == SHORT_ANS_YESNO:\n",
        "      label_yes_no_train_accuracy.reset_states()\n",
        "    else:\n",
        "      start_train_accuracy.reset_states()\n",
        "      end_train_accuracy.reset_states()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      i = 0\n",
        "      for inputs in dist_train_ds:\n",
        "        train_step(inputs, task)\n",
        "        i = i + 1\n",
        "        \n",
        "        training_result = f\"epoch: {epoch}, batch: {i}, loss: {train_loss.result()}, \"\n",
        "        if task == SHORT_ANS_YESNO:\n",
        "          training_result += f\"label_yes_no_train_accuracy: {label_yes_no_train_accuracy.result()*100}\"\n",
        "        else:\n",
        "          training_result += f\"start_accuracy: {start_train_accuracy.result()*100}, end_accuracy: {end_train_accuracy.result()*100}\"\n",
        "        print(training_result)\n",
        "\n",
        "        train_loss.reset_states()\n",
        "        if task == SHORT_ANS_YESNO:\n",
        "          label_yes_no_train_accuracy.reset_states()\n",
        "        else:\n",
        "          start_train_accuracy.reset_states()\n",
        "          end_train_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSJmGOkZ-jy-",
        "colab_type": "code",
        "outputId": "62001822-95ef-4c28-97f2-49d59cc6fce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9c8282ea745d48db891417749e7584e6",
            "a52589dc373846eb9d87b7aa5e3c806f",
            "dbd496aa7e3e4753ae4dcd9ad5f22a5b",
            "3225434038114e1683afe1b7432cbd39",
            "d7da15a0a1a94c079a8ad4a83c04157e",
            "9e585a3b86f14539993e9af758d3fb04",
            "a303f92dc71d4793813c55c3675a4f36",
            "da8b163e6d2d441ea9ae8bc2eb2940e8"
          ]
        }
      },
      "source": [
        "train_short_ans_using_tpu(dist_train_ds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c8282ea745d48db891417749e7584e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=534, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING:tensorflow:AutoGraph could not transform <function train_short_ans_using_tpu.<locals>.train_step at 0x7fe11de17d90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Cell is empty\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function train_short_ans_using_tpu.<locals>.train_step at 0x7fe11de17d90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Cell is empty\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function train_short_ans_using_tpu.<locals>.train_step at 0x7fe11de17d90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Cell is empty\n",
            "epoch: 0, batch: 1, loss: 0.061213620007038116, label_yes_no_train_accuracy: 50.0\n",
            "epoch: 0, batch: 2, loss: 0.028606656938791275, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 0, batch: 3, loss: 0.014323508366942406, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 0, batch: 4, loss: 0.009018322452902794, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 0, batch: 5, loss: 0.0055490778759121895, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 1, batch: 1, loss: 0.00454691331833601, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 1, batch: 2, loss: 0.0035286354832351208, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 1, batch: 3, loss: 0.0029887082055211067, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 1, batch: 4, loss: 0.12542632222175598, label_yes_no_train_accuracy: 50.0\n",
            "epoch: 1, batch: 5, loss: 0.0025311214849352837, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 2, batch: 1, loss: 0.0023513445630669594, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 2, batch: 2, loss: 0.0021745646372437477, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 2, batch: 3, loss: 0.002134285168722272, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 2, batch: 4, loss: 0.0021534310653805733, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 2, batch: 5, loss: 0.128073588013649, label_yes_no_train_accuracy: 50.0\n",
            "epoch: 3, batch: 1, loss: 0.002107578096911311, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 3, batch: 2, loss: 0.0023579862900078297, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 3, batch: 3, loss: 0.0025717373937368393, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 3, batch: 4, loss: 0.0030161843169480562, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 3, batch: 5, loss: 0.0031795529648661613, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 4, batch: 1, loss: 0.002793410327285528, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 4, batch: 2, loss: 0.0029999813996255398, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 4, batch: 3, loss: 0.002912756986916065, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 4, batch: 4, loss: 0.0026584789156913757, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 4, batch: 5, loss: 0.0023383316583931446, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 5, batch: 1, loss: 0.002730616834014654, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 5, batch: 2, loss: 0.0020647644996643066, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 5, batch: 3, loss: 0.0018381602130830288, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 5, batch: 4, loss: 0.0018058542627841234, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 5, batch: 5, loss: 0.0017196906264871359, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 6, batch: 1, loss: 0.12586036324501038, label_yes_no_train_accuracy: 50.0\n",
            "epoch: 6, batch: 2, loss: 0.0017743224743753672, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 6, batch: 3, loss: 0.0018913417588919401, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 6, batch: 4, loss: 0.001893920823931694, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 6, batch: 5, loss: 0.00232885405421257, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 7, batch: 1, loss: 0.002484553027898073, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 7, batch: 2, loss: 0.0019875343423336744, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 7, batch: 3, loss: 0.002556568244472146, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 7, batch: 4, loss: 0.0021336874924600124, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 7, batch: 5, loss: 0.0031768723856657743, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 8, batch: 1, loss: 0.003009808249771595, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 8, batch: 2, loss: 0.0028809374198317528, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 8, batch: 3, loss: 0.002518055494874716, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 8, batch: 4, loss: 0.0024502058513462543, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 8, batch: 5, loss: 0.0021846177987754345, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 9, batch: 1, loss: 0.0020677391439676285, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 9, batch: 2, loss: 0.0016892899293452501, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 9, batch: 3, loss: 0.12119760364294052, label_yes_no_train_accuracy: 50.0\n",
            "epoch: 9, batch: 4, loss: 0.0019951225258409977, label_yes_no_train_accuracy: 100.0\n",
            "epoch: 9, batch: 5, loss: 0.0019355199765414, label_yes_no_train_accuracy: 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f89RPSsU-sEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}